<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>图神经网络在分布电路设计中的应用</title>
      <link href="/2021/08/15/gnn-circuit-design/"/>
      <url>/2021/08/15/gnn-circuit-design/</url>
      
        <content type="html"><![CDATA[<blockquote><p>数学上，图是节点以及节点之间关系的集合，任意尺寸上的物体在任意空间上能够以任意形式发生连接，就可以构成一个图，从这个角度讲，一切关系皆是图。<br>而从关系的角度看世界，大到宇宙中星球之间的引力关系，城市中交通道路网的交错关系，社交网络中人与人之间的好友互访关系，小到蛋白质网络中的交互关系，化合物分子中原子间化合键关系，纳米集成电路中器件与器件之间的布局关系，几乎万物可以看做以某种关系连接起来，继而都可以视作一个图。</p></blockquote><h2>引文</h2><p>现在大家的手机基本上都是5G手机，从2G到4G、5G信号的变化，本质上就是信号频率的增大，在以后的6G时代，信号的频率会进一步升级。而当信号频率不断增大后，对相关的芯片设计提出了更高的挑战，这其中的一个关键器件就是谐振器，谐振器就是让某个（或某段）频率信号通过，阻挡其他频率信号，达到选泽的目的，主要起到频率控制的作用，所有电子产品涉及频率的发射和接收都需要谐振器（比如射频芯片）。</p><p>近日，谷歌大脑团队在《Nature》发布了一篇使用图神经网络和强化学习实现芯片布局的paper，其中提到可以在6小时内生成符合工业生产要求的芯片布局，并已应用到下一代谷歌TPU的生成设计中。GNN应用与芯片电路设计吸引了笔者的兴趣，通过调研，2019年MIT团队发表了一篇GNN应用于芯片布局的代表性paper(<a href="http://proceedings.mlr.press/v97/zhang19e.html" target="_blank" rel="noopener">Circuit-GNN: Graph Neural Networks for Distributed Circuit Design</a>)，本文即对此进行解读。</p><p>该文章通过将高频谐振器中元器件之间的关系（相对空间距离）构造成一种边，从图的角度出发，提出了一种使用图神经网络（GNN）方法进行高效设计滤波器电路的方法。下面主要从以下几点进行展开：</p><ol><li>背景介绍：介绍基本电路器件及性能参数</li><li>GNN方法</li><li>实验与效果</li><li>总结与启发</li></ol><h2>一、背景介绍</h2><h3>1.1 谐振器及$s_{21}$参数</h3><p>通常谐振器有三种，环形、棒性和方形，一个滤波器可由多个谐振器组合而成，并有一个输入和输出端口，输入信号通过输入端口后，其中特定频段的信号被放大输出，其他频率的就被阻挡或者反射，谐振器的参数包括，通常用$s_{21}$系数来进行性能评估<br><img src="dut.jpeg" width="80%" height="80%"></p><p>如上图所示，对于一个两端口的电子元器件DUT，输出信号a1从端口1进入后，会产生两个信号：1端口的反射信号b1，端口2的输出信号为b2，信号通常为正弦波的形式，b1和b2通常会发生相位变化或者幅度衰减，以调幅为例，b1和a1两个信号幅值的比值$s_{21}$为插入损耗，也就是有多少能量被传输到目的端（端口2），这个值越大越好，理想值是1，并用20*log$s_{21}$转化dB形式，通常为负值，当$s_{21}=\frac{1} {10}$时为-20dB。</p><p>进一步的，针对不同频率 $\omega_{i}$的输入信号，DUT的$s_{21}$可以看作是不同频率下的参数叠加，表示为：$s_{21}(\omega) =  \sum_{i=1}^N \frac {a_i} {j\omega - b_i}$，$\frac {a_i} {j\omega_i - b_i}$表示在频率 $\omega_{i}$ 的输入信号下该器件的性能参数，其中$a_i, b_i$为复数参数，分别表征幅值和相位的变化。</p><h3>1.2 现有的解决方案及其缺不足</h3><p>传统的人工电路设计非常依赖专家的经验，同时花费的时间比较高，随着AI技术的发展，一些深度学习方法也逐渐得到应用，其核心是预测参数$a_i, b_i$。下图所示为深度学习应用于芯片电路设计的流程抽象图，在前向过程中，模型将给定的电路映射为相应的转移函数（$s_{21}$），并通过曲线进行刻画;反向过程中，模型将梯度进行回传，更新模型权重和电路拓扑结构来更好的拟合$s_{21}$。<br><img src="illustration.png" width="90%" height="90%"><br>但是，现有的基于深度学习的方法，通常面对不同的基板需要单独设计一个模型，并通过更改其中的参数（谐振器个数、类型、排布等）来进行有监督的训练，学习到面对当前template的模型。另外有些情况下需要再增加一个模型来挑选不同基板下的最佳模型，实用性比较局限；同时，现有的深度学习方法通常只能限定一个参数，未实际解决模型梯度如何反馈到电路设计的变动上。</p><h2>二、GNN方法</h2><h3>2.1 前向过程</h3><h4>1 边的定义和节点特征</h4><p>一个正方向谐振器视为一个节点，其参数包含位置和尺寸，表示为$[x,y,a,\theta]^T$，其中$x、y$为平面坐标，$a$为边长，$\theta$为槽的角位置</p><p>谐振器i，j之间的边属性定义为$[\theta_{i},\theta_{j}, x_i-x_j, y_i-y_j, g_{ij}, s_{ij}]$，其中$x_i-x_j,y_i-y_j$为相对偏移位置，$g_{ij}, s_{ij}$表示间隔gap的长度和偏移，节点和边的定义可以参见下图：</p><img src="node.png" width="90%" height="90%"><p>同时考虑到电磁耦合会随着距离筛检，对距离设置了阈值。</p><h4>2. GNN endoding</h4><p>有了节点和边的定义以及属性后，一个template下所有的谐振器就构成了一张图，那么就可以使用GNN方法进行图表示学习。在每一层GNN中，节点和边的特征更新步骤如下：</p><ul><li><p>更新边的特征<br>第$t$层网络中$i, j$节点的特征更新依赖于 $t-1$ 层当前边的特征$e_{ij}$以及边上的两个节点特征，并通过$f_e^t$（MLP）进行映射,具体为</p><p>$$e_{ij}^t = f_e^t (\eta_i^{t-1}, \eta_j^{t-1}, e_{ij}^{t-1})$$</p></li><li><p>更新节点的特征<br>第$t$层网络中 $i$ 节点的特征更新依赖于 $t-1$ 层当前节点的特征$ \eta^{t-1}_i$ 以及所有的关联边特征，并通过$f_n^t$（MLP）进行映射,具体为</p><p>$$\eta_{i}^{t} = f_n^{t} (\eta_i^{t-1},\sum_j e_{ij}^{t})$$</p></li></ul><h4>3. 图池化</h4><p>通常GNN应用于graph-level任务时，最后的池化操作时将图中所有节点的嵌入特征进行池化作为整体的特征，而本文中仅仅使用了电路中与输入、输出端口连接的两个谐振器节点的特征，通过拼接作为最终的全局表示。</p><h4>4. 预测</h4><p>在图表示之后使用MLP进行预测，表示进行直接进行预测，输出的为多个采样频率的复数形式$s_{21}$参数，假设采样m个频率，那么$\hat{y}\triangleq[S_{21}(\omega_1),…, s_{21}(\omega_m)]^T$,其中$\omega_i $表示从频率带宽$\Omega \triangleq [\omega_{min}, \omega_{max}]中的采样$。在训练的时候，Loss定义为：</p><p>$$<br>\mathcal{L}(\theta) = \mathbb{E}_{r,y \sim D} ||\real {(\hat {y} (r;\theta)} - \real(y))||_1 + || \image (\hat {y} (r;\theta) - \image(y))||_1<br>$$<br>其中，$r \in \Reals ^{N \times 4} $为芯片参数，$\theta$为模型参数，最小误差包含复数参数中实数和虚数两部分，$D$为训练数据集。</p><p>如下图所示，整个过程可概括为四步：</p><ol><li>构图</li><li>GNN学习</li><li>特征抽取为全局表示</li><li>预测</li></ol><img src="gnn.png" width="100%" height="100%"><h3>2.2 反向优化</h3><h4>loss设计对带通滤波器的loss函数改造</h4><p>对于带通滤波器，要求特定频率范围内的信号才能通过，那么可以将该频率的标签设置为$y_i = 1$，非该频率的设置为0，则优化目标为二分类，相应的目标函数为：<br>$$<br>\mathcal{J} = \sum\limits_{i:\omega_i \in \Omega^\star}(|\hat {y_i}| - 1)^2 + \sum\limits_{i:\omega_i \notin \Omega^\star}|\hat y_i|^2<br>$$</p><h4>梯度如何反馈到布局的改变</h4><p>反向迭代时，第$i$谐振器每次随机选择一个方向$d_i \in {(-1, 0), (1, 0), (0, -1), (0, 1)}$进行移动，当方向确定后，预先计算出该谐振器在该方向上能够移动的最大距离$m_i$，那么，当前谐振器下一次移动方式定义为：<br>$$<br>p_i = p_i^{\star} + \sigma(q_i)m_{i}d_i<br>$$<br>其中$p_i^{\star}$为节点的当前坐标为止，$q_i$为学习参数，$\sigma(q_i)$为偏移比例。下图为每个谐振器选定方向后的最大移动距离示意图：</p><img src="move.png" width="90%" height="80%"><h2>三、实验与效果</h2><h3>3.1 数据集</h3><p>本文使用方形谐振器，并分别使用了谐振器数量为3、4、5、6的电路template进行学习，并用商业套件CST STUDIO SUIT生成标签，模型评估指标为$s_{21}$的幅值平均绝对误差:<br>$$<br>\epsilon_{db}(\hat y, y) \triangleq \frac {1} {m} \sum\limits_{i=1}^{m}|20log(|y_i|) - 20log(|\hat y_i|)|<br>$$</p><h3>3.2 训练</h3><p>总共100000个数据样本，训练集为80%的4、5模板样本，其他全部为测试集，模型表现如下：<br><img src="dataset.png" width="90%" height="90%"><br>时间性能上，在1080Ti的nvidia显卡上，GNN模型单次预测50ms，比商业套件CST STUDIO SUIT快4个数量级。同时，文中也展示了一些good和bad cases，如下图所示（其中虚线为groud truth， 虚线为GNN模型）：<br><img src="good.png" width="90%" height="90%"><br><img src="bad.png" width="90%" height="90%"></p><h3>3.3 性能评估</h3><h4>与人类专家对比</h4><img src="bandpass.png" width="90%" height="90%">上图中有三个带通滤波器，－6dB为通频带（大于－6dB的频率都可以通过），可以看到专家设计和GNN模型都达到了标准，细心点会发现，GNN模型的曲线峰值离0更近，即损失更小。<h4>与商业软件对比</h4><p>给定带宽滤波器设计参数，其带宽和中心频率分别从[20, 40]GHz 和[235, 315]GHz进行采样得到，对商业软件CST和GNN模型的输出。为了衡量模型针对带宽滤波器的设计能力，引入两个指标：<br><strong>Pass-band IOU</strong>: 衡量滤波电路的带宽与目标带宽的相近程度，具体为两个带宽中频率的交集数量除以并数量集，类似于Jaccard相似度，越大越好<br><strong>Insertion Loss</strong>：$s_{21}$峰值的绝对值，越小越好<br>针对每个设计目标，CST从450个仿真中挑一个最好的，GNN从10个候选中挑一个最好的，总共采样了60个设计任务，最终评估CDF曲线如下图所示，可以看到在两项指标上GNN都好与CST，去CDF=0.5得到均值指标，GNN的通频带IOU为0.80优于CST的0.73， GNN的insertion loss为4.13dB优于CST的4.92dB。<br><img src="cdf.png" width="90%" height="90%"></p><h2>四、总结与启发</h2><ul><li>本文第一个基于深度学习解决了面向多种template进行芯片设计的问题</li><li>本文第一个基于深度学习解决了芯片设计的反向问题：即给定电路的电磁（滤波频率）特性，通过深度学习的梯度回传来优化模型参数，反向进行芯片设计</li><li>本文介绍了一种将图模型的梯度回传与布局设计耦合的方法，可以应用到其他涉及到节点具有几何或空间意义的图模型场景中</li><li>本文使用了输入和输出端口直连的谐振器嵌入特征来表征全图，而不是将图中所有节点的嵌入特征进行聚合这种通常做法，经验上对其他类似场景具有指导意义，例如两个蛋白分子交互作用时，可能只有部分特殊状态的原子才能够成键，因此可以将这些代表性的特定原子的嵌入特征拼接来表示整个蛋白质分子，而不是对所有原子进行聚合。</li></ul>]]></content>
      
      
      <categories>
          
          <category> paper </category>
          
          <category> graph </category>
          
          <category> gnn </category>
          
      </categories>
      
      
        <tags>
            
            <tag> circuit </tag>
            
            <tag> gnn </tag>
            
            <tag> graph </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ICML-2021图相关论文汇总</title>
      <link href="/2021/06/04/icml-2021-graph/"/>
      <url>/2021/06/04/icml-2021-graph/</url>
      
        <content type="html"><![CDATA[<h1>ICML-2021图相关论文汇总</h1><h2>数据统计</h2><p>数据统计转自博主Sergey Ivanov，几个有意思的统计如下：</p><p>不同大学的paper分布</p><img src="大学.jpg" width="90%" height="90%"><p>不同机构的paper分布<br><img src="num_orga.png" width="90%" height="90%"></p><p>中国机构的paper分布</p><img src="中国机构.jpg" width="90%" height="90%"><p>美国机构的paper分布</p><img src="美国机构.jpg" width="90%" height="90%"><p>全截图</p><img src="all-twetter1.jpg" width="90%" height="90%"><h2>图论文清单</h2><p>官网链接：<a href="https://icml.cc/Conferences/2021/AcceptedPapersInitial" target="_blank" rel="noopener">https://icml.cc/Conferences/2021/AcceptedPapersInitial</a></p><ol><li><strong>Two Heads are Better Than One: Hypergraph-Enhanced Graph Reasoning for Visual Event Ratiocination</strong> <em>Wenbo  Zheng (School of Software Engineering, Xi’an Jiaotong University）, Lan Yan （The State Key Laboratory for Management and Control of Complex Systems, Institute of Automation, Chinese Academy of Sciences）, Chao Gou (School of Intelligent Systems Engineering, Sun Yat-sen University）, Fei-Yue Wang (The State Key Laboratory for Management and Control of  Complex Systems, Institute of Automation, Chinese Academy of Sciences）</em></li><li><strong>Deep Latent Graph Matching</strong> <em>Tianshu Yu (Arizona  State University）, Runzhong Wang (Shanghai Jiao Tong University）,  Junchi Yan (Shanghai Jiao Tong University）, baoxin Li (Arizona State  University）</em></li><li><strong>On Explainability of Graph Neural Networks      via Subgraph Explorations</strong> <em>Hao Yuan (Texas A&amp;M University）,      Haiyang Yu (Texas A&amp;M University）, Jie Wang (University of Science      and Technology of China）, Kang Li (Rutgers）, Shuiwang Ji (Texas A&amp;M      University）</em></li><li><strong>GRAND: Graph Neural Diffusion</strong> <em>Ben Chamberlain      (Twitter）, Maria Gorinova (University of Edinburgh）, Michael Bronstein      (Twitter）, Stefan Webb (Twitter）, James Rowbottom (Twitter）, Emanuele      Rossi (Twitter）</em></li><li><strong>Optimization of Graph Neural Networks:      Implicit Acceleration by Skip Connections and More Depth</strong> <em>Keyulu Xu (MIT）,      Mozhi Zhang (University of Maryland）, Stefanie Jegelka (Massachusetts      Institute of Technology）, Kenji Kawaguchi (MIT）</em></li><li><strong>Theory of Spectral Method for Union of      Subspaces-Based Random Geometry Graph</strong> <em>Gen Li (Tsinghua University, China）,      Yuantao Gu (Tsinghua University）</em></li><li><strong>Differentially Private Densest Subgraph      Detection</strong> <em>Dung      Nguyen (University of Virginia）, Anil Vullikanti (Biocomplexity      Institute and Dept of Computer Science, University of Virginia）</em></li><li><strong>Information Obfuscation of Graph Neural      Networks</strong> <em>Peiyuan      Liao (Carnegie Mellon University）, Han Zhao (University of Illinois at      Urbana-Champaign）, Keyulu Xu (MIT）, Tommi Jaakkola (MIT）, Geoff Gordon      (Carnegie Mellon University）, Stefanie Jegelka (Massachusetts Institute      of Technology）, Ruslan Salakhutdinov (Carnegie Mellen University）</em></li><li><strong>Generative Causal Explanations for Graph      Neural Networks</strong> <em>Wanyu      LIN (University of Toronto）, Hao Lan (University of Toronto）, Baochun      Li (University of Toronto）</em></li><li><strong>How Framelets Enhance Graph Neural Networks</strong> <em>Xuebin Zheng (The      University of Sydney）, Bingxin Zhou (The University of Sydney）, Junbin      Gao (The University of Sydney）, Yuguang Wang (Max Planck Institute for      Mathematics in Sciences; Shanghai Jiao Tong University; University of New      South Wales）, Pietro Lió (University of Cambridge）, Ming Li (Zhejiang      Normal University）, Guido Montufar (UCLA Math / Stat; MPI MIS）</em></li><li><strong>GraphNorm: A Principled Approach to      Accelerating Graph Neural Network Training</strong> <em>Tianle Cai (Princeton University）,      Shengjie Luo (Peking University）, Keyulu Xu (MIT）, Di He (Microsoft      Research）, Tie-Yan Liu (Microsoft Research Asia）, Liwei Wang (Peking      University）</em></li><li><strong>Self-supervised Graph-level Representation      Learning with Local and Global Structure</strong> <em>Minghao Xu (Shanghai Jiao Tong University）     , Hang Wang (Shanghai Jiao Tong University）, Bingbing Ni (Shanghai Jiao      Tong University）, Hongyu Guo (National Research Council Canada）, Jian      Tang (HEC Montreal &amp; MILA）</em></li><li><strong>Let’s Agree to Degree: Comparing Graph      Convolutional Networks in the Message-Passing Framework</strong> <em>Floris Geerts      (University of Antwerp）, Filip Mazowiecki (MPI-SWS）, Guillermo Perez      (UAntwerpen）</em></li><li><strong>GraphDF: A Discrete Flow Model for Molecular      Graph Generation</strong> <em>Youzhi      Luo (Texas A&amp;M University）, Keqiang Yan (Texas A&amp;M University,      College Station）, Shuiwang Ji (Texas A&amp;M University）</em></li><li><strong>GLSearch: Maximum Common Subgraph Detection      via Learning to Search</strong> <em>Yunsheng Bai (UCLA）, Derek Xu (University of California, Los      Angeles）, Yizhou Sun (UCLA）, Wei Wang (UCLA）</em></li><li><strong>Compositional Video Synthesis with Action      Graphs</strong> <em>Amir      Bar (Tel Aviv University）, Roi Herzig (Tel Aviv University/ UC Berkeley）     , Xiaolong Wang (UCSD）, Anna Rohrbach (UC Berkeley）, Gal Chechik      (NVIDIA / Bar-Ilan University）, Trevor Darrell (University of California      at Berkeley）, Amir Globerson (Tel Aviv University, Google）</em></li><li><strong>Memory-Efficient Graph Neural Networks</strong> <em>Guohao Li (KAUST）,      Matthias Müller (Intel Labs）, Bernard Ghanem (KAUST）, Vladlen Koltun      (Intel Labs）</em></li><li><strong>A Unified Lottery Ticket Hypothesis for      Graph Neural Networks</strong> <em>Tianlong Chen (University of Texas at Austin）, Yongduo Sui      (University of Science and Technology of China）, Xuxi Chen (University      of Texas at Austin）, Aston Zhang (AWS AI）, Zhangyang Wang (University      of Texas at Austin）</em></li><li><strong>Flow-based Attribution in Graphical Models:      A Recursive Shapley Approach</strong> <em>Raghav Singal (Amazon）, George Michailidis      (University of Florida）, Hoiyi Ng (Amazon）</em></li><li><strong>Discrete-Valued Latent Preference Matrix      Estimation with Graph Side Information</strong> <em>Changhun Jo (University of      Wisconsin-Madison）, Kangwook Lee (UW Madison）</em></li><li><strong>Directional Graph Networks</strong> <em>Dominique Beaini      (InVivo AI）, Saro Passaro (University of Cambridge）, Vincent Létourneau      (Université de Ottawa）, Will Hamilton (McGill University and Mila）,      Gabriele Corso (University of Cambridge）, Pietro Lió (University of      Cambridge）</em></li><li><strong>World Model as a Graph: Learning Latent      Landmarks for Planning</strong> <em>Lunjun Zhang (University of Toronto）, Ge Yang (University of      Chicago）, Bradly Stadie (Vector Institute）</em></li><li><strong>Graph Cuts Always Find a Global Optimum for      Potts Models (With a Catch）</strong> <em>Hunter Lang (MIT）, David Sontag      (Massachusetts Institute of Technology）, Aravindan Vijayaraghavan      (Northwestern University）</em></li><li><strong>Graph Contrastive Learning Automated</strong> <em>Yuning You (Texas      A&amp;M University）, Tianlong Chen (University of Texas at Austin）,      Yang Shen (Texas A&amp;M University）, Zhangyang Wang (University of      Texas at Austin）</em></li><li><strong>Graph Mixture Density Networks</strong> <em>Federico Errica      (University of Pisa）, Davide Bacciu (University of Pisa）, Alessio      Micheli (Universita di Pisa）</em></li><li><strong>Automated Graph Representation Learning with      Hyperparameter Importance Explanation</strong> <em>Xin Wang (Tsinghua University）, Shuyi Fan      (Tsinghua University）, Kun Kuang (Tsinghua University）, wenwu zhu      (Tsinghua University）</em></li><li><strong>Symmetric Spaces for Graph Embeddings: A      Finsler-Riemannian Approach</strong> <em>Federico Lopez (HITS - Heidelberg Institute      for Theoretical Studies）, Beatrice Pozzetti (Heidelberg University）,      Steve Trettel (Stanford University）, Michael Strube (Heidelberg      Institute for Theoretical Studies）, Anna Wienhard (Heidelberg      University）</em></li><li><strong>Skill Discovery for Exploration and Planning      using Deep Skill Graphs</strong> <em>Akhil Bagaria (Brown University）, Jason Senthil (Brown      University）, George Konidaris (Brown）</em></li><li><strong>E(n） Equivariant Graph Neural Networks</strong> <em>Víctor Garcia      Satorras (University of Amsterdam\）, Emiel Hoogeboom (University of Amsterdam）, Max Welling (University of Amsterdam &amp; Qualcomm）</em></li><li><strong>LEGO: Latent Execution-Guided Reasoning for      Multi-Hop Question Answering on Knowledge Graphs</strong> <em>Hongyu Ren      (Stanford University）, Hanjun Dai (Google Brain）, Bo Dai (Google Brain）     , Xinyun Chen (UC Berkeley）, Michihiro Yasunaga (Stanford University）,      Haitian Sun (Google）, Dale Schuurmans (Google / University of Alberta）,      Jure Leskovec (Stanford University）, Denny Zhou (Google Brain）</em></li><li><strong>Order Matters: Probabilistic Modeling of      Node Sequence for Graph Generation</strong> <em>Xiaohui Chen (Tufts University）, Xu Han      (Tufts University）, Jiajing Hu (Tufts University）, Francisco R Ruiz      (DeepMind）, Liping Liu (Tufts University）</em></li><li><strong>Towards Better Laplacian Representation in      Reinforcement Learning with Generalized Graph Drawing</strong> <em>Kaixin Wang      (National University of Singapore）, Kuangqi Zhou (National University of      Singapore）, Qixin Zhang (city university of hong kong）, Jie Shao ( Fudan  University）, Bryan Hooi (National University of Singapore）, Jiashi Feng      (National University of Singapore）</em></li><li><strong>Spectral vertex sparsifiers and pair-wise      spanners over distributed graphs</strong> <em>Chunjiang Zhu (University of North Carolina      Greensboro）, Qinqing Liu (University of Connecticut）, Jinbo Bi      (University of Connecticut）</em></li><li><strong>SGA: A Robust Algorithm for Partial Recovery      of Tree-Structured Graphical Models with Noisy Samples</strong> <em>Anshoo Tandon      (National University of Singapore）, Aldric Han (National University of      Singapore）, Vincent Tan (National University of Singapore）</em></li><li><strong>Graph Convolution for Semi-Supervised      Classification: Improved Linear Separability and Out-of-Distribution      Generalization</strong> <em>Aseem      Baranwal (University of Waterloo）, Kimon Fountoulakis (University of      Waterloo）, Aukosh Jagannath (University of Waterloo）</em></li><li><strong>Lipschitz normalization for self-attention      layers with application to graph neural networks</strong> <em>George Dasoulas      (Ecole Polytechnique, Paris, France）, Kevin Scaman (Noah’s Ark, Huawei      Technologies）, Aladin Virmaux (Huawei）</em></li><li><strong>Online Graph Dictionary Learning</strong> <em>Cédric Vincent-Cuaz      (INRIA Sophia Antipolis）, Titouan Vayer (IRISA）, Rémi Flamary (École      Polytechnique）, Marco Corneli (Université Côte d’Azur）, Nicolas Courty      (UBS）</em></li><li><strong>Breaking the Limits of Message Passing Graph      Neural Networks</strong> <em>Muhammet      Balcilar (Université de Rouen - LITIS）, Pierre Heroux (University of      Rouen Normandy）, Benoit Gauzere (INSA Rouen）, Sebastien Adam      (Université de Rouen Normandie）, Paul Honeine (LITIS Lab, Université de      Rouen Normandie）, Pascal Vasseur (LITIS Université de Rouen Normandie）</em></li><li><strong>Towards Open Ad Hoc Teamwork Using      Graph-based Policy Learning</strong> <em>Muhammad Arrasy Rahman (The University of      Edinburgh）, Niklas Hopner (University of Amsterdam）, Filippos      Christianos (University of Edinburgh）, Stefano Albrecht (University of      Edinburgh）</em></li><li><strong>From Local Structures to Size Generalization      in Graph Neural Networks</strong> <em>Gilad Yehudai (Weizmann Institute of      Science）, Ethan Fetaya (Bar-Ilan University）, eli meirom (NVIDIA）, Gal      Chechik (Nvidia）, Haggai Maron (NVIDIA Research）</em></li><li><strong>GNNAutoScale: Scalable and Expressive Graph      Neural Networks via Historical Embeddings</strong> <em>Matthias Fey (TU Dortmund University）, Jan      Eric Lenssen (TU Dortmund）, Frank Weichert (Technical University of      Dortmund）, Jure Leskovec (Stanford University）</em></li><li><strong>Local Graph Algorithms for Learning      Higher-Order Structures</strong> <em>Peter Macgregor (The University of Edinburgh）, He Sun      (University of Edinburgh）</em></li><li><strong>Improving Molecular Graph Neural Network      Explainability with Orthonormalization and Induced Sparsity</strong> <em>Ryan Henderson      (Bayer）, Djork-Arné Clevert (Bayer AG）, Floriane Montanari (Bayer AG）</em></li><li><strong>Directed Graph Embeddings in      Pseudo-Riemannian Manifolds</strong> <em>Aaron Sim (BenevolentAI）, Maciej Wiatrak      (BenevolentAI）, Angus Brayne (BenevolentAI）, Páidí Creed (BenevolentAI）     , Saee Paliwal (Benevolent AI）</em></li><li><strong>Interpretable Stability Bounds for Spectral      Graph Filters</strong> <em>Henry      Kenlay (University of Oxford）, Dorina Thanou (Swiss Data Science Center      (EPFL and ETH Zurich））, Xiaowen Dong (University of Oxford）</em></li><li><strong>Unbiased Gradient Estimation in Unrolled      Computation Graphs with Persistent Evolution Strategies</strong> <em>Paul Vicol      (University of Toronto）, Luke Metz (Google Brain）, Jascha      Sohl-Dickstein (Google Brain）</em></li><li><strong>Controlling Graph Dynamics with      Reinforcement Learning and Graph Neural Networks</strong> <em>Eli Meirom (NVIDIA      Research）, Haggai Maron (NVIDIA Research）, Shie Mannor (Technion）, Gal      Chechik (NVIDIA / Bar-Ilan University）</em></li><li><strong>Stochastic Iterative Graph Matching</strong> <em>Linfeng Liu (Tufts      University）, Michael C. Hughes (Harvard University）, Soha Hassoun (）,      Liping Liu (Tufts University）</em></li><li><strong>Improving Breadth-Wise Backpropagation in      Graph Neural Networks helps Learning Long-Range Dependencies.</strong> <em>Denis Lukovnikov      (University of Bonn）, Asja Fischer (Ruhr University Bochum）</em></li><li><strong>DeepWalking Backwards: From Embeddings Back      to Graphs</strong> <em>Sudhanshu      Chanpuriya (University of Massachusetts Amherst）, Cameron Musco      (University of Massachusetts Amherst）, Konstantinos Sotiropoulos (Boston      University）, Charalampos Tsourakakis (ISI Foundation, Boston University）</em></li><li><strong>Expressive 1-Lipschitz Neural Networks for      Robust Multiple Graph Learning against Adversarial Attacks</strong> <em>Xin Zhao (Auburn      University）, Zeru Zhang (Auburn University）, Zijie Zhang (Auburn      University）, Lingfei Wu (IBM Research AI）, Jiayin Jin (Auburn      University）, Yang Zhou (Auburn University）, Ruoming Jin (Kent State      University）, Dejing Dou (&quot; University of Oregon, USA&quot;）, Da      Yan (University of Alabama at Birmingham）</em></li><li><strong>Context-Aware Online Collective Inference      for Templated Graphical Models</strong> <em>Charles Dickens (UCSC）, Connor F Pryor      (UCSC）, Eriq Augustine (University of California, Santa Cruz）,      Alexander Miller (UCSC）, Lise Getoor (University of California Santa      Cruz）</em></li><li><strong>Integrated Defense for Resilient Graph      Matching</strong> <em>Jiaxiang      Ren (Auburn University）, Zijie Zhang (Auburn University）, Jiayin Jin      (Auburn University）, Xin Zhao (Auburn University）, Sixing Wu (Peking      University）, Yang Zhou (Auburn University）, Yelong Shen (Microsoft      Dynamics 365 AI）, Tianshi Che (Auburn University）, Ruoming Jin (Kent      State University）, Dejing Dou (&quot; University of Oregon, USA&quot;）</em></li><li><strong>Elastic Graph Neural Networks</strong> <em>Xiaorui Liu      (Michigan State University）, Wei Jin (Michigan State University）, Yao      Ma (Michigan State University）, Yaxin Li (Michigan State University）,      Hua Liu (Shandong University ）, Yiqi Wang (Michigan State University）,      Ming Yan (Michigan State University）, Jiliang Tang (Michigan State      University）</em></li><li><strong>Z-GCNETs: Time Zigzags at Graph      Convolutional Networks for Time Series Forecasting</strong> <em>Yuzhou Chen      (Southern Methodist University）, Ignacio Segovia (University of Texas at      Dallas）, Yulia R Gel (University of Texas at Dallas）</em></li><li><strong>Hierarchical Agglomerative Graph Clustering      in Nearly Linear Time</strong> <em>Laxman Dhulipala (MIT CSAIL）, David Eisenstat (Google）,      Jakub Łącki (Google）, Vahab Mirrokni (Google Research）, Jessica Shi      (MIT）</em></li><li><strong>Size-Invariant Graph Representations for      Graph Classification Extrapolations</strong> <em>Beatrice Bevilacqua (Purdue University）,      Yangze Zhou (Purdue University）, Bruno Ribeiro (Purdue University）</em></li><li><strong>Scalable Optimal Transport in High      Dimensions for Graph Distances, Embedding Alignment, and More</strong> <em>Johannes Klicpera      (Technical University Munich）, Marten Lienen (Technical University of      Munich）, Stephan Günnemann (Technical University of Munich）</em></li><li><strong>Graph Neural Networks Inspired by Classical      Iterative Algorithms</strong> <em>Yang Yongyi (Fudan University）, Tang Liu (Fudan University）     , Yangkun Wang (SJTU）, Jinjing Zhou (Amazon）, Quan Gan (Amazon）,      Zhewei Wei (Renmin University of China）, Zheng Zhang (Amazon）, Zengfeng      Huang (Fudan University）, David Wipf (Microsoft Research）</em></li></ol>]]></content>
      
      
      <categories>
          
          <category> paper </category>
          
          <category> graph </category>
          
      </categories>
      
      
        <tags>
            
            <tag> graph </tag>
            
            <tag> icml </tag>
            
            <tag> paper </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>应用当前AI最先进技术预测股票走势【翻译】</title>
      <link href="/2019/11/07/ai-for-stock-prediction/"/>
      <url>/2019/11/07/ai-for-stock-prediction/</url>
      
        <content type="html"><![CDATA[<p>这是从medium上看到的一篇用当前各种牛逼AI技术进行股价趋势预测的神文，原文已经被点赞上万次，Github上star数1.7k，<a href="https://towardsdatascience.com/aifortrading-2edd6fac689d" target="_blank" rel="noopener">原文链接</a>，<a href="https://github.com/borisbanushev/stockpredictionai" target="_blank" rel="noopener">GitHub链接</a>。相信绝大部分人初看这篇文章，都会惊叹于其涵盖技术范围之广泛、理论实战之兼并，以及似乎重新点燃了多少在股票价格预测中折戟并深以为股价不可预测的众生，尤其看到末尾作者贴出的模型预测结果，无不令人大喊一声卧槽。但，所谓事出反常必有妖，这么牛逼这么准确的股价预测模型难道没有过拟合或者其他错漏吗？</p><p>作者没有在Github上放出数据和模型源码，仅是在notebook中贴出了部分代码，自从作者今年1月份放出文章后似乎就闭关了，再无任何更新，对众多评论与issue都没回复，不得不引人注意的是，博客评论和issue中频繁出现的两点质疑：</p><ol><li>傅立叶变换不当使用：特征工程中的傅里叶变换进行构造的时候似乎是对全部数据进行变换，而不是仅针对训练集，这样存在数据泄漏的问题。</li><li>缺乏关键科学性结果：文章中缺乏关键实验结果，无准确度等评价指标，无baseline对比，没有用其他股票样本进行预测等等。</li></ol><blockquote><p>作为一个集大成的AI技术应用于股价趋势预测的神文，其框架中各种技术应用的逻辑和角度还是值得肯定，尤其是行文中不乏科普讲解，作为一篇综述也很有可取之处。<br>本文在对其做翻译的基础上，力争不引入一个公式，同时加入一些更本土化的知识和自己的理解，与君共享。由于整个体系涉及的知识面太过广泛，难免有浅薄之处，还请海涵。</p></blockquote><h1>1. 引言</h1><p>股价作为一个庞杂的系统，其精准预测历来是一个极其高难度的事情，因为各种事件的偶发性，多种类多人群的情绪博弈。要进行股价预测，那就要先做一些前提假设来让它符合可预测的条件：</p><ol><li>市场不是完全随机（比如有预期，情绪煽动）</li><li>历史会重复（照葫芦画瓢，刻舟求剑）</li><li>市场以人的意志为转移（所有人的博弈，甚至坐庄）</li><li>市场是“完美”的（不完美的市场就不好预测了）</li></ol><h1>2. 数据</h1><p>本文以美股纽约证券交易所上市的Goldman Sachs（NYSE: GS）作为目标，预测其股价涨跌。分别使用 1585 天和 680 天的股价数据作为训练集和测试集（分别占比70%，30%），除了股价这种原始特征外，其他特征数据还包括：</p><ol><li>关联资产：诸如板块趋势、汇率、指数等</li><li>技术指标：比如MACD，布林线，5/10/20天线</li><li>基本面指标：包括公司评估指标ROE、PE，公司日报（文本提取后情感分类）等。当然由于不同来源不同，直觉地可认为不同来源的特征应该赋予不同的权重，即注意力机制也可以派上用场</li><li>傅里叶变换：时序数据提取频域特征（不恰当类比，耳朵听到的一个钟声，在频域上就是一个静止的音符）</li><li>ARIMA：时序预测的经典模型，二阶差分组合的线性模型，可以用来去噪和特征提取</li><li>Stacked autoencoders：典型的就是神经网络，用来挖掘隐含特征，通俗来说就是用另一个角度看数据。部分前面提到的特征是相关研究人员多年总结提炼出来的，但特征之间隐含着的关联信息是不容易被捕捉到的,举个粗糙的例子，例如ROE &gt; k + MACD交叉 + 行业主营产品价格上涨 + 国际top工厂相关业务调整策略 这样几个因子我们还比较好挖掘，但如果成千上万个因子作为特征输入时，相互之间的关联信息是很难的，而autoencoders的设计就是用来挖掘隐信息的。</li></ol><h2>2.1 特征</h2><p>针对不同的特征数据采取何种技术进行提取呢？像关联资产、技术指标、傅里叶变换、ARIMA这些数字指标不需要过多笔墨，一两个公式就可以得到。但像从研报等文本数据中提取特征，就涉及到自然语言处理了。</p><p>本文作者使用的是谷歌提出来的<strong>BERT</strong>框架，一种预训练了的语言表示模型，本质还是可以理解为一种高阶版本的Word2Vec（本博客第一篇有提到），借用单词与单词能组合构成一句话，句子与句子组合构成文章的这种关联，通过一定方式能够得到每个单子每个句子的数字化表达，一个直接的感官是数字化后的同义词之间的距离也更接近，比如说女王和夫人的点坐标距离就比女王和苹果更接近。</p><p>BERT 模型的应用有两种方式，一种是 fine-tune（微调） 方法，一种是 feature extract（特征抽取） 方法。fine tune方法指的是加载预训练好的 Bert 模型，其实就是一堆网络权重的值，当做一个初始化的参数，是一种常见的迁移学习手段。<br>feature extract（特征抽取）方法指的是调用预训练好的 Bert 模型，对新任务的句子做句子编码，将任意长度的句子编码成定长的向量。编码后，作为你自己设计的某种模型（例如 LSTM、SVM 等都由你自己定）的输入，等于说将 BERT 作为一个句子特征编码器，这种方法没有反向传播训练过程，简单来说就是一个函数，把句子变为数字特征。</p><p>本文采用的正是feature extract，另外BERT也有中文版本，github有集成了bert的keras、pytorch等接口的开源库。</p><h2>2.2 特征工程</h2><p>由于特征过多，需要做一些特征筛选或者叫预处理，包括剔除异方差、多重共线性、序列相关等，这些都是统计上经常需要考量的。</p><h3>回归分析</h3><p>多重共线性（Multicollinearity）是指线性回归模型中的自变量之间由于存在高度相关关系而使模型的权重参数估计失真或难以估计准确的一种特性，多重是指一个自变量可能与多个其他自变量之间存在相关关系。因为传统的统计线性回归中都是假设各个变量之间的独立同分布，例如一件商品的销售数量可能与当地的人均收入和当地人口数这两个其他因素存在相关关系，所以预测利润的时候这三个变量都放进去就会出现多重共线性。多重共线性会导致模型预测方差变大，置信度降低，自然地就出现了多重共线性检验方法、残差分析等。</p><p>但在机器学习模型中，对数据就没有独立同分布这样的假设，线性模型会有惩罚项（Lasso/Ridge）来应对，非线性模型比如决策树，它在节点分裂的时候选择增益最大的特征作为分裂的特征也不会有这样的问题。归根结底还是不做假设，只通过目标函数最优化求解来避免了，这可能也是梯度求解和OLS之间的一些差异吧。</p><h3>XGBoost</h3><p>经过所有的特征处理后，可能特征依然还是太多（吐槽，可能是没见过生物数据，先天的特征数远大于样本数），但不是所有的特征都是有价值的，或者特征可能会很冗余不利于计算，本文作者采用XGBoost来进行权重的挑选。XGBoost是一种决策树模型，每一个节点就是一个特征分裂点，按照增益最大化的策略进行分裂，详细的理论阐述可以参见博客<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>（PS：不过个人建议是使用LightGBM，后起之秀，相对XGBoost做了不少优化，速度更快）。由于特征众多，作者只用XGBoost对技术指标进行了特征权重测试，并发现所有特征都值得被保留，所测试的特征及其权重见下图，从图中可见，MA7、MACD权重更高。<br><img src="xgboost.png" width="50%" height="40%"></p><h3>Autoencoder</h3><p>前面提到，自编码机是用来提取特征的隐含表示的，可以理解为把输入特征先A转化为B（大部分是做了降维），然后重新转换变为A，也就是构造了两个映射，先A -&gt; B 再从B-&gt;A返还为也是输入，中间的B就是我们挖掘出来的多特征之间的隐含信息。其通常实现方式是多层神经网络，如下图所示，中间绿色就是我们所有得到的目标B。</p><img src="auto.jpeg" width="40%" height="40%"><p>本文通过Autoencoder获得了112维度的特征，之后实验性地使用PCA进一步进行了特征降维。自此，特征全部构建完毕。</p><h1>3. GAN</h1><img src="gan.jpeg" width="90%" height="90%"><p>GAN被称为“左右互搏术”，由生成器$G$（模仿）和判别器$D$（裁判）两大部分构成，给定真实数据（通常是图片），希望通过模型学到数据的分布。两部分的具体功能是：</p><ol><li>生成器：使用随机初始化的数据试着去生成和真实数据一样分布的数据。</li><li>判别器: 真实的数据和城市的数据投喂给后面的判别器进行判断，判别器试着分别出输入来自于生成器还是真实样本。</li></ol><p>在训练的时候，也是分阶段分布训练$G$和$D$，第一阶段：固定$D$，训练$G$，第二阶段：固定$G$，训练$D$，第三阶段：不断迭代以上两步。所以，生成器$G$的目标就是尽量生成真实的数据去欺骗判别器$D$，而判别器D的目标就是尽量把$G$生成的图片和真实的图片分别开来。这样，$G$和$D$构成了一个动态的“博弈过程”。最后博弈的结果是什么？在最理想的状态下，$G$可以生成足以“以假乱真”的图片$G(z)$。对于$D$来说，它难以判定G生成的图片究竟是不是真实的，因此$D(G(z)) = 0.5$。</p><p>因此，GAN模型有几下几个有点：</p><ul><li>能更好的建模原始数据的分布</li><li>不需要生成器满足比如高斯分布的条件</li><li>可以不用通常在复杂的概率生成模型中出现的变分推断或者MCMC采样</li></ul><p>但也有几个缺点：</p><ul><li>难训练，不稳定，生成器和判别器之间需要很好的同步，但是在实际训练中很容易$D$收敛，$G$发散。</li><li>模式崩塌（Mode Collapse）问题。GANs的学习过程可能出现生成器开始退化，总是生成同样的样本点，无法继续学习。</li></ul><p>因此也出现了许多改进的GAN模型，比如典型的DCGAN、WGAN等，本文在此不展开。</p><h2>3.1 为什么选择GAN？</h2><p>通常GAN被用来生成图片、视频，几无用于时序数据的预测。然而GAN的本质还是概括数据的分布，一个不失偏颇的假设是股票的模式和行为在时间上是或多或少具有一致性的，所以理论上，从历史数据中生成具有相同分布的未来数据是可行的。于是，作者使用LSTM作为时序预测的生成器，使用CNN用作判别器。</p><h2>3.2 MHGAN and WGAN</h2><p>如果可以训练一个完美的生成器，那么生成器最终的概率密度函数应与真实数据的概率密度函数相同。然而，许多现有的 GAN 无法很好地收敛到真实数据的分布 ，因此从这种不完美的生成器中抽样会产生看起来不像原始训练数据的样本。另一方面，判别器中却包含有原始真实数据分布的信息，可用于生成器的校正。如果我们有一个完美的判别器 D 和一个不完美的生成器 $G$，使用 $p(D)$ 而不是 $p(G)$ 作为生成的概率密度函数等价于使用一个新的生成器 $G’$，并且这个 $G’$是可以完美地模拟真实数据分布的。那么，如果结合D来构造新型的生成器成为了GAN的一个发展重要的方向。<br>Metropolis-Hastings GAN（MHGAN）就是随着这样的想法由Uber提出来的，另一个比较经典的是Google提出的判别器拒绝重采样（Discriminator Rejection Sampling，DRS）。MHGAN是继续保留$D$，每次$G$生成k个输出后，$D$首先生成k个生成样本的判别概率，然后通过MH采样方法最终输出一个生成样本。而DRS与MHGAN的区别是采样方式的区别，之所以采样来近似原始的分布，是因为原始分布本身不太好直接求得。</p><p>由于上文中提到的GAN不稳定等缺点，本文采用了改进的Wasserstein GAN（WGAN），主要是舍弃来传统的两个分布相似度度量的KL散度，采用了Wasserstein distance作为损失函数，更详细的理论可以查看其论文。</p><h2>3.3 生成器-RNN</h2><h3>LSTM/GRU</h3><p>RNN通常用来做时序预测，因为其能结合先前所有时间点的信息，发现时序中的模式。RNN的两个经典代表是GRU和LSTM，二者在结构设计上有些许不一样，但在大部分场景中二者输出表现差不多，但LSTM被更多的使用。更多理论详细介绍，可以查阅论文或参考<a href="https://zybuluo.com/hanbingtao/note/581764" target="_blank" rel="noopener">LSTM博客</a></p><h2>3.4 判别器-CNN</h2><p>CNN能够逐层提取特征，因而在图像中广泛使用，例如在动物图像识别中，浅层卷积网络会捕获到边的信息，更深一层的开始检测圆形，再继而检测到鼻子、嘴型等，知道能识别出整体。而在股票预测中，一些点形成小趋势，一些小趋势形成更大趋势，直到形成一种模式，这种特征适合CNN来捕捉。此外，CNN先天对数据的空间信息能更有效的利用，即空间上临近的点能够同时被处理，在股票应用中则是临近时间的数据应该比更远时间的点更亲近。当然股价的周期性也是应用CNN需要考虑的。</p><p><code>作者提示：使用CNN用来时序数据的预测只是实验性的尝试，未有理论上的证明。</code></p><h1>4. 超参数优化</h1><p>常见的超参数有：网络结构，包括神经元之间的连接关系、层数、每层的神经元数量、激活函数的类型；优化参数，包括优化方法、学习率、小批量的样本数量；正则化系数等等。<br>而超参数优化主要存在两方面的困难：</p><ul><li>超参数优化是一个组合优化问题，牵一发而动全身，无法像一般参数那样通过梯度下降法来优化。</li><li>评估一组超参数配置的时间代价非常高，从而导致一些优化方（如演化算法等）在超参数优化中难以应用。每调整一次超参数必须重新训练才能评估效果，这在模型很大的时候效率会非常低。<br>对于超参数设置，比较简单的方法有人工搜索、网格搜索和随机搜索。</li></ul><p>参数调优是大家比较熟悉的是随机搜索、网格搜索，进阶版的有贝叶斯优化，进化算法，这些都是在比较固定的超参数空间中进行最优配置搜索，而最重要的神经网络架构一般还是需要由有经验的专家来进行设计。于是，神经网络搜索应运而生，其出现就是为了解决如何通过机器策略和自动化的方式设计出优秀高效的网络，2017年谷歌大脑就使用强化学习的搜索方法。</p><p>本文也借用了强化学习的思想，尝试在超参数优化的过程中，引入强化学习的机制来调配贝叶斯优化器进行参数更新。具体来说，就是在GAN训练每200个epochs时记录MAE，然后将其投喂到强化学习中来决定是否更新参数。</p><h2>4.1 强化学习</h2><p>由于股票瞬息万变，即使当前训练的模型能够得到比较好的结果，但这结果也可能是短期时间区间内比较有效，而模型参数不变的情况下，长期表现就不佳，这里面符合直觉的假设是<strong>股票趋势是随着时间动态变化的</strong>。所以模型长期的优化就显得很有必要，而这时候强化学习就派上用场了，方式包括特征的增删以及模型优化（主要还是调参）。<br>提示：本章是探索性研究，强化学习也只是超参调优的一个方式。</p><h3>4.1.1 强化学习理论</h3><p>一个比较简单生动的强化学习例子是“巴普洛夫的狗”：每次给狗送食物以前打开红灯、响起铃声。这样经过一段时间以后，铃声一响或红灯一亮，狗就开始分泌唾液。其实这是培养了狗狗的后天条件反射，如果把我们的模型比如成“狗狗”，那么模型训练目标就可以类比为让”狗狗“学会一种条件反射，比如alpha Go就是让它学会对方每下一步棋，“狗狗”能下出一步大概率稳赢的棋。既然是后天习得，训练中必须要有反馈，巴普洛夫是用铃声和红灯当了正向的奖励性质刺激物，那么必然的反响调节的惩罚刺激也是有的。就像泡脚时水温冷了加点热水，烫了就加点冷水这种正反方向的不断调节来达到预期目标，强化学习里也存在这样的机制。<br>假设有一个智能体，它可以根据外部环境采取行动从而改善自己的状态，同时获得奖励，而强化学习就是这样一个智能体与环境不断发生交互的循环过程。这种过程有一个专有的学名叫：“马尔可夫决策过程”，所谓马尔可夫是指当前状态只与上一个状态有关，与之前历史上其他任何状态无关的一种定义，而要理解马尔可夫过程，需要先介绍一个基本概念：<br>1. 状态（state） 智能体在每个步骤中所处的状态集合<br>2. 行为（action）智能体在每个步骤中所能执行的动作集合<br>3. 转移概率（transition）智能体处于状态s下，执行动作a后，回转移到另一个状态s‘的概率<br>4. 奖励（reward）智能体处于状态s下，执行完动作a后，转移到状态s’后获得的立即奖励<br>5. 策略（policy）智能体处于s下，应该执行动作a的概率<br>马尔可夫过程在不断迭代的过程中，在满足一定条件下（大部分情况都是可以直接假设满足条件），数学上可以证明马尔可夫过程必定达到一个稳定状态，即马尔可夫收敛性，收敛性意思就是说迭代次数多了是可以找到最优解的。而且马尔可夫过程的应用领域非常广，在强化学习、机器学习、运筹学、生物进化、粒子物理等等领域中都有发挥作用。在一个规划问题上，我亲身见识到了用天河计算机暴力穷举都无法在有效时间内破解的难题被马尔可夫给解决了。马尔可夫过程挺有趣的，简单粗暴，但是蕴含着深刻的数据哲理，哲理就不展开了。</p><h3>4.1.2 Rainbow</h3><p>本文使用了一种无模型的强化学习框架Rainbow，并定义reward为GAN中G和D两模块中的指标LossG 、LossD和AccG的线性组合，action定义为超参数的调整。</p><p>Rainbow是一种融合了多种Q-learning改进方法的深度强化学习算法。<br>Q-learning是强化学习中的valve-based算法，Q即$Q(s,a)$表示的是在某一时刻的s状态下采取动作a获得的收益的期望，与环境反馈的reward、财务动作变化前后的value都有关，每次使用最优的Q来更新$Q(s,a)$同时采取相应动作，迭代直到收敛（还记得前面提到的马尔可夫收敛性吗？）。不同（有限）的 $(s, a)$ 组合的Q值构成一个表格称为Q-table，收敛后的Q-label就是当前问题的最优解，可以看一个<a href="zhuanlan.zhihu.com/p/35882937">经典迷宫小游戏</a>的例子。</p><p>Rainbow融合的方法(参阅博客<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>)：</p><ol><li>DQN：深度Q-网络，大多数情况下描述所有的状态和动作的Q-table是很困难的，毕竟s和a的值空间可能是非常多，有限内存无法全部概括。于是，值函数的思想被派上了用场：一个函数，输入为s和a，输入为Q，于是目标变成为拟合一个函数，能够实现(s,a)到Q的映射，属于机器学习的回归范畴，继而有监督方法中诸如线性回归、决策树甚至神经网络都可以应用进来，而DQN就是使用神经网络来代替Q-table。具体里面的训练样本、loss构建可参阅相关文献。</li><li>Double Q Learning：DQN作者在设计模型的时候，提供了两个解决器：1，replay buffer，强化学习训练时会把历史上的动作状态组合值按时间循序保存在经验回放池中，然后可以利用随机均匀采样经验池中样本数据提供给智能体训练而不是每次只用当前最新的状态；2，fixed Q-target，DQN使用定期迭代更新的方式更新目标值计算中的拟合网络参数，而不是一直更新。但是，在标准的DQN中，取最大值的操作都是使用相同的Q值来选择和评估下一个action，这样一直选择最优的action会容易出现过拟合，所以Double Q使用增加了另外一套参数，一套参数决定了greedy方式找到最优解的值空间，另外一套参数决议值空间中挑选值，而之前的参数是默认直接搜索并返回一个最优值。</li><li>Prioritized Experience Replay：标准DQN构建了一个replay buffer并均匀采样，而PER要解决的问题是如何最有效地选择经验回放池中的样本进行学习，也就是利用历史资料衡量每个动作序列样本的重要性，按不同权重值进行采样。</li><li>Dueling networks：在DQN中神经网络直接输出每个动作的Q值，而Dueling DQN输出的Q值则有两部分构成：Q= 状态价值V+优势函数A，优势函数的作用是，对一个特定状态，采取一个动作所能得到的价值与这个状态能得到的平均价值的区别，如果相比平均价值大，那么优势函数为正，反之为负，有点像均值归一化作为附加的注意力机制。</li><li>Noisy Nets：通过学习网络权重的扰动来促进策略的探索，主要认为对权重向量的微小更改会造成多个时间步中引发一致且可能非常复杂的状态相关的策略的更改。NoisyNets就是在构建网络的时候加入高斯扰动，增加模型的鲁棒性，本质上是多加了一些参数让网络更复杂来一点。</li><li>Categorical DQN：其核心思想是通过模型概括出奖惩值的分布，而不是之前像之前DQN学习的是分布的期望。</li><li>Multi-step Learning：每一步中不再是计算当前动作和状态值，而是通过计算后面N步的值来决定当前的Q值。<br>这些对Q-learning的改进有点类似于SGD、Adam中的演进机理，从计算的有效、速度上的快慢与贪婪、鲁棒性等等角度对模型做满足一定假设条件下的优化，让每一度迭代更安全更稳定更高效。</li></ol><h3>4.1.2 PPO</h3><p>Rainbow中的各种算法顺是基于值函数（Value-based），还有基于策略（Policy-based）的如确定性策略梯度算法DPG，以及第三种基于深度强化学习的信赖域优化（Trust Region based），信赖域（Trust Region）方法指在该区域内更新，策略所实现的回报值单调不减，典型代表就是PPO、TRPO、ACER等。其实主要是解决基于策略的深度强化学习中步长收敛的问题而提出来的，现在很多好的算法和方法都是用了这样的方法。</p><p>近端策略优化（Proximal Policy Optimization，PPO）是一种model-free类型的强化学习方法，2017年由OpenAI提出，OpenAI做的打dota的也是用PPO实现的，其优势是可以直接学习策略而不是通过学习Q矩阵来推导策略，在连续动作空间中很有效。 据介绍这种算法用在强化学习中时表现能达到甚至超过现有算法的顶尖水平，同时还更易于实现和调试，总之是简单高效。但从来没有免费的午餐，PPO要达到不错的效果，但其对迭代次数非敏感。</p><h2>4.2 贝叶斯优化</h2><p>机器学习模型超参数调优一般认为是一个黑盒优化问题，所谓黑盒问题就是我们在调优的过程中只看到模型的输入和输出，不能获取模型训练过程的梯度信息，也不能假设模型超参数和最终指标符合凸优化条件，否则的话我们通过求导或者凸优化方法就可以求导最优解，不需要使用这些黑盒优化算法，而实际上大部分的模型超参数也符合这个场景。另外模型的训练过程是相对计算量大的，不能通过快速计算获取大量样本，因而大家都很熟悉的自动调参算法Grid search在相当多场景下难以适用，相继的有许多调参方法，比较出名的有Random search和贝叶斯优化。Random search其实就是随机搜索，通常在相同次数下结果一般比Grid search最值会更大，当然variance也更大，但仍然是一种搜索方法，未能利用之前的搜索结果，而贝叶斯优化就是从这一点着手，利用先前经验来更好的挑选参数。</p><p>贝叶斯方法的一个基本思想是利用先验知识逼近未知目标函数的后验分布从而调节超参，即先假设目标函数（如准确率、召回率、F 值等）为一个特定的先验分布（通常是高斯过程），然后用不同的采样数据点去估计，用迭代的方式不断对初始分布进行修正，它的本质其实是一种回归模型，利用回归模型预测的函数值来选择下一个搜索点。值得一提的是，这里的样本点是指一组超参数，而不是通常意义上的样本点。<br>贝叶斯优化里面有两个需要设计，一个是统计模型，比如高斯过程（多元高斯分布）；一个是采样函数,决定下一个采样点。贝叶斯优化根据先验分布，假设采集函数而学习到目标函数的形状，如下图所示，Online metric可以与模型评估函数一致（如MSE），阴影区域代表方差，高斯估计代表均值；下半区域代表采样函数，每次根据最大Expected Improvement来选择采样点，其中Expected Improvement只是多种采样指标的一种，还有的指标是采样点均值和方差的组合。而不同采样函数的设计与改进，都是为了解决一个问题：如何在开发（exploitation）和探索（exploration）之间权衡，即模型到底是在当前最优解进一步开发，还是在尚未取样的区域获取采样点，从而尽量避开局部最优解。<br><img src="bo_1d_opt.gif" width="100%" height="100%"></p><p>与常规的网格搜索或者随机搜索的区别是：</p><ul><li>贝叶斯调参采用高斯过程，考虑之前的参数信息，不断地更新先验；网格搜索未考虑之前的参数信息</li><li>贝叶斯调参迭代次数少，速度快；网格搜索速度慢, 参数多时易导致维度爆炸</li><li>贝叶斯调参针对非凸问题依然稳健；网格搜索针对非凸问题易得到局部优最</li></ul><h1>5 结果</h1><p>使用强化学习进行10个episodes，每个episodes表示GAN训练200个epochs的结果如下图：<br><img src="final_result.png" width="100%" height="100%"></p><h1>6 免责声明</h1><p>本文信息丰富，但任何内容不构成对证券投资组合的特定投资交易策略有效性的推荐。股票有风险，投资需谨慎。</p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>XGBoost原理剖析，<a href="https://www.csuldw.com/2019/07/20/2019-07-20-xgboost-theory/" target="_blank" rel="noopener">https://www.csuldw.com/2019/07/20/2019-07-20-xgboost-theory/</a> <a href="#fnref1" class="footnote-backref">↩</a></p></li><li id="fn2" class="footnote-item"><p>Rainbow拆解及源码实现，<a href="https://www.kukuxiaai.com/blog/2019-07/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B9%8B-rainbow/" target="_blank" rel="noopener">https://www.kukuxiaai.com/blog/2019-07/强化学习算法之-rainbow/</a> <a href="#fnref2" class="footnote-backref">↩</a></p></li></ol></section>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
          <category> model </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 股票 </tag>
            
            <tag> GAN </tag>
            
            <tag> 强化学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>下酒吃菜之投资笔记(一)：半导体芯片与封装</title>
      <link href="/2019/10/10/stock-survey-led/"/>
      <url>/2019/10/10/stock-survey-led/</url>
      
        <content type="html"><![CDATA[<p>今年年初在女朋友的无意提及下，二月中旬将京东金融中的理财资金大部分转入某混合指数基金（定投方式），之后于三月中旬开通证券账户，自此开启了“韭菜投资”之路。从起初的小幅试水到如今的缓慢加仓，从时事新闻热门动态五花八门的不吝凤毛麟角到上下游供应链的行业聚焦，从典型的追赃杀跌低卖高买到网格止损止盈低买高卖，从如厕饮水间的频繁胡乱操作到持股不疑的买定里手，从股价起伏的如痴如癫到合理波动的冷眼看淡，小韭菜终于还是从小仓微盈到大仓亏损，算是交了入门的学费。</p><blockquote><p>既然上学了不免要交点作业，于是将自己的部分市场行业调研笔记整理出来，遂成此文。</p></blockquote><h2>三安光电分析</h2><p>近期在5G热潮下，科技板块中的<code>三安光电</code>显著拉升，但并不是走的LED芯片路线，而是国产替代下的5G第三代半导体（砷化镓，氮化镓）加速国产化。</p><p>化合物半导体作为半导体材料，砷化镓（GaAs）、氮化镓（GaN）和碳化硅（SiC）半导体分别作为第二代和第三代半导体的代表，砷化镓和氮化镓的主要应用都是射频前端的功率放大器等器件，某些标的受益 5G 逻辑，机构已经发掘了一年了，但股价一直没有大幅表现，原因是基本上产业还是被国外龙头（主要是美国公司）所把持，国内相对比较落后，真正的龙头三安在行业低谷期又深陷财务泥潭。但此次股价的表现，真正的预期差在于，由于今年的<strong>华为事件</strong>，华为在未来在射频前端需要去美国化，而且会选择国产供应商替代。</p><ul><li>化合物半导体<br>砷化镓：主要以智能手机射频前端、5g 基础设施应用为主。近年来国家积极推动 5G 网络建设和商用化，4G/5G 通讯对射频器件有更高要求，未来 5g 手机中的 GaAs 器件数量将会增加 1-2 倍。从 Yole Development等第三方研究机构估算来看，2017 年全球用于 PA 的 GaAs 器到件市场规模达到 80-90 亿美元，大部分的市场份额集中于 Skyworks、Qorvo、Avago 三大巨头。预计随着通信升级未来两年有望正式超过 100 亿美元。</li></ul><p>氮化镓：应用在汽车电子功率变频芯片、快充和军工方面，功率半导体的硅基板 GaN 技术市场，氮化镓射频器件高速成长，下游市场结构整体保持稳定。研究机构 Yole Development 数据显示，2017 年氮化镓射频市场规模为 3.8 亿美元，将于 2023 年增长至 13 亿美元，复合增速为22.9%。下游应用结构整体保持稳定，以通讯与军工为主，二者合计占比约为 80%。</p><h3>宏观层面</h3><p>正当贸易战，5G 升级+国产替代双轮驱动成长背景下化合物半导体实现国产自给自足已成为必然趋势。国内射频芯片龙头从上市卓胜微以来已暴涨近10倍。近期科技板块热潮有向上材料端蔓延的趋势，例如三安广电、云南锗业等砷化镓产业链相关企业都受到关注。日前，国家集成电路产业投资基金（二期）（简称“大基金二期”）的募资工作已经完成，规模在2000亿元左右，对集成电路产业链实属重大利好。<br>晶圆制造：重点投资了中芯国际，总投资将近160亿元，华力二期项目投入116亿元，以及上海华虹。</p><p>其中，第一期大基金投资半导体产业链公司如下：<br>存储器制造：大基金和紫光集团投资了长江存储科技公司<br>特色工艺制造：投资了杭州士兰微<br>化合物半导体制造：投资了三安光电<br>封装测试：投资了长电科技、通富微电和华天科技等<br>设计领域：投资了紫光展锐、中兴微电子<br>装备领域：投资了北方微和中微半导体，大基金重点推进了北方微与七星电子整合，组成北方华创，目前北方华创已成为国内最大的半导体装备企业，同时中微半导体的刻蚀机已在部分企业的大生产线上得到应用。</p><h3>中观层面</h3><p>在2015年的一则研报《三安光电：产业基金继续支持，砷化镓继续看好》中提到，三安光电在砷化镓等化合物半导体加大投入，并且有大基金加持，节选片段如下：</p><blockquote><p>产业基金继续支持,砷化镓有望再造三安：继“国家集成电路产业投资基金”(简称为大基金)以48.39亿受让三安集团持有的上市公司9.07%的股份后,大基金通过本次非公开发行股份的认购，又一次对公司GaAs业务予以支持。本次非公开发行拟投入16亿用于通讯微电子器件(一期)项目，以GaAs和GaN等III-V族半导体为核心打造集成电路产业；该项目建成后将形成年产30万片GaAs和GaN年产6万片的产能：预计达产年销售收入401,539万元，新增年净利润59,624万元，有望再造一个三安。GaAs和GaN是通讯领域不可取代的半导体材料，技术门槛高，国家支持将为公司提供强有力的后盾。</p></blockquote><h4>LED行业发张趋势</h4><p>LED 产业链分为上游芯片、中游封装、下游显示和照明，A股相关上市企业19年中报的原籍汇总如下：</p><img src="led-中报.png" width="90%" height="90%"><p>从半年报数据来看，LED 产业链上下游均出现低迷，各板块均录得负增长，主要原因是各方前期库存量巨大情况下恶意的价格战导致的毛利率变低。上游芯片公司毛利率下滑甚至转负，中游及下游毛利率则回升。上游五家芯片公司中，澳洋顺昌与华灿光电上半年 LED 芯片毛利率均转为负值，这是<strong>重资产高折旧行业在周期底部常见的情形</strong>，三安光电毛利率仍位居第一，但是毛利率已经降至 20%出头。封装、显示、照明环节毛利率则普遍有所上升，包括 LED 芯片在内的原材料价格下降，给了中下游毛利率提升的空间。企业毛利率趋势图如下：</p><img src="led-毛利率.png" width="80%" height="100%"><p>而年初小牛以来，各大基金和指数皆有不小的涨幅，LED板块受累于库存，整体涨幅不大，其与沪深300指数对比如下：</p><img src="led-300.png" width="60%" height="60%"><h3>公司层面</h3><p><strong>三安光电</strong>主要从事全色系超高亮度LED外延片、芯片、Ⅲ-Ⅴ族化合物半导体材料、微波通讯集成电路与功率器件、光通讯元器件等的研发、生产与销售，产品性能指标居国际先进水平。三安中国LED市场份额29%；拥有1400多项专利，持续保持同样的芯片面积比竞争对手亮度高5%；提供国内第一条6寸氮化镓生产线。建立国内由手机芯片厂→ PA厂→SAW厂的垂直供应链策略联盟布局，替代进口，稳定RF原件市场。立足于III-V族化合物半导体材料，打造具有国际竞争力的射频、滤波器集成电路厂商。虽然 LED 芯片行业短期库存仍然较高，未来仍有去库存去产能的压力。但公司 PB 估值目前已处于历史底部区域。而公司化合物半导体目前获得产业链上下游的高度支持，有望获得突破，将提升公司中长期盈利增长空间。</p><p>三安集成作为国内化合物半导体制造平台龙头，立足国内广阔市场，面向全球高端需求。公司产品工艺布局较为完善，产品类别涵盖射频、电力电子、光通讯和滤波器板块，18 年在职员工已突破 800 人，营收约 1.71 亿元，出货客户累计至 73 家，出货产品达 270 种。随着公司砷化镓、光通讯产品逐渐受到客户大量验证使用，氮化镓和碳化硅产品逐渐由研发导入量产，2019年起出货量将会逐步增长，近期的股价上涨在三季报应该会有呈现。</p><p>库存分析：上半年龙头三安光电存货周转天数达到 243 天，创下历史记录，主要是LED芯片竞争激烈，价格相比去年同期降幅较大。</p><img src="三安-存货.png" width="80%" height="100%"><p>现金流质量分析：现金流质量稳中有升。</p><img src="三安-营收.png" width="80%" height="100%"><p>作为国内最大的Ⅲ-V族化合物半导体、集成电路龙头企业以及国内LED芯片的领导者，三安光电在全球的市场占有率接近二成，且仍在继续扩充产能。2013年至2017年，三安光电保持着业绩连增五年的成绩，2018年，LED行业整体需求下行，该公司的盈利随之下滑。</p><p>据三安光电半年报披露，公司旗下的泉州三安半导体项目顺利推进，部分设备进入安装调试阶段，预计下半年部分产能开始逐步释放。7月底，三安光电Mini/Micro LED显示芯片产业化项目在湖北省鄂州市葛店经济技术开发区开工，项目总投资333亿元，预计建设7个产业化项目。</p><p>在射频代工领域，三安集成在国内市场进展加快，获得更多工艺平台的客户认证，公司产品量产节奏加快。在电力电子领域，公司已推出成熟的 650V/1200V SiC 器件工艺，并已获得包括北美客户在内的行业客户的认证及订单；GaN 器件相关工艺将于 2019 年第三季度完成所有工艺可靠性认证并推向市场。光通讯领域在发射及接收端，面向传统通信市场以及新兴的 5G 相关市场、数据中心及消费类市场，均已推出成套解决方案。</p><h2>小结</h2><p>目前股价阶段性上涨后呈震荡状态，三安光电当前市盈率20.25，获北上资金加仓，股价整体仍处于低位。另外，大基金前后投入约64.4亿，持仓成本为约22.36元，目前仍处于套牢中。</p><p>LED行业触底，化合物放量成新增长主力之际，就是三安光电化身真龙之时。</p><hr><h2>国星光电分析</h2><ul><li>Mini（小间距） LED<br>Mini LED：小身材，大市场，高增长。作为一种在小间距 LED 基础上所衍生出的新型 LED 显示技术，mini LED 也被称为“亚毫米 LED”。由于具备优良的显示效果、较长的寿命和出色的性价比，mini LED 自诞生以来便广受关注，其下游应用可覆盖 RGB 显示屏、笔记本电脑背光、电视背光、手机背光、车载显示等诸多领域。</li></ul><p>与 LCD 显示相比，小间距 LED 显示器具有无拼缝、高亮度和无反射图像的优点，其应用范围已从政府的公共信息显示扩展到商业显示。随着 LED 显示屏于租赁市场、HDR 市场应用、零售百货、会议室市场需求增加，小间距乃至于超小间距显示屏景气度将持续向好。而mini LED 技术作为小间距显示屏的自然延伸，无论下游应用还是工艺技术均可无缝衔接，有望为 LED 显示屏注入新的源头活水。</p><h3>宏观层面</h3><p>今年年初，工业和信息化部、国家广播电视总局、中央广播电视总台联合发布了《超高清视频产业发展行动计划（2019-2022年）》，《行动计划》提出了到2022年我国超高清视频产业的发展目标，在政策引导和各方资源积极投入下，产业总体规模有望超过4万亿元，超高清视频用户数达到2亿，4K产业生态体系基本完善，8K关键技术产品研发和产业化取得突破，形成技术、产品、服务和应用协调发展的良好格局。<br>2019年倍称为5G元年，5G商用助推超高清视频产业快速发展，mini LED 高清终端有望率先受益。</p><h3>中观层面</h3><p>LED作为显示技术的重要元件，透过技术不断突破，使显示屏在节能、显示效果上都能持续进步，尤其是Mini LED背光、Mini LED RGB以及Micro LED的出现，更满足不同取向的显示技术。其中Mini LED背光在经过近三年的努力开发后，已于2018下半年正式导入市场。</p><p>集邦咨询LED研究中心（LEDinside）最新《2019中国LED芯片与封装产业市场报告》显示，2018年中国LED封装市场规模为105亿美金，同比增长4.5%。展望2019年，LED照明已经进入成熟期，期待高端照明，如专业照明与健康照明的市场需求，紫外LED、车用照明和显示屏市场将是LED产业增长的主要推动力。</p><p>LEDinside在最新的《2019 Mini LED与HDR高阶显示器市场报告》中指出，苹果近期发表一款采用全新LED背光方案的Pro Display XDR 32寸6K显示器，带动显示器产业积极找寻高端产品的新技术方案，而下一代Mini LED背光技术将是各家厂商的开发重点，接下来将与OLED正面对决，成为面板产业的新契机。预估至2023年Mini LED背光产值将达3.4亿美元（仅Mini LED背光产值，不含其他驱动IC与背板）。</p><p>随着产业链各大厂商的协同发力，mini LED 这个诞生不久的行业新秀已然呈现出星火燎原之势。Yole 数据显示：全球 miniLED 显示设备将有望从 2019年的 3.24 百万台，增长至 2023 的 80.7百万台，年复合增长率高达 90%。</p><p>此外，5G 商用助推超高清视频产业快速发展，随着 5G 商用稳步推进，更大带宽、更高网速必将促进超高清视频产业链不断完善和快速成长，而以手机、电视为代表的高清终端作为产业链中至关重要的一环，则有望率先受益。mini LED 背光显示屏无论从画质、饱和度、对比度均能达到 4K、6K、8K 的显示效果，且产品寿命和性价比均显著优于 OLED 显示方案，将有望成为各主流厂商超高清显示终端的最适宜选择。</p><p>并且，在车载显示中不管是采用 OLED 显示屏，还是采用传统的 TFT LCD显示屏，在制造成本与驾驶安全上，仍然有着很多不足。而 Mini LED属于在传统LED背光+TFT LCD显示屏的改良版本，采用直下式发光，精细的 HDR 分区显示，在对比度大幅提升，可以实现低余辉待机外，能耗也大幅降低，还具有比 OLED 更好的高温可靠性更高，寿命与TFT LCD 一样长。基于上述逻辑可以认为：随着技术的进一步成熟，车载显示市场将会成为 mini LED 背光继手机、电视以后的另一片蓝<br>海。<br>日前，苹果申请的一项与Micro LED相关的专利“验证微器件转移的光学验证系统”获批。Patently Apple消息显示，美国专利商标局（the US Patent and Trademark Office）已公布的苹果Micro LED专利有好几项，涉及于Micro LED芯片转移和结构，AR显示及可折叠设备。</p><blockquote><p>据传荣耀智慧屏计划用mini的，最后还是用了量子点膜。而目前苹果和华为都有Mini LED供应链传出来的消息。<br>可见，在应用终端上头部企业都在积极布局，技术成熟后必将给供应链带来极大效益。</p></blockquote><h3>公司层面</h3><p><strong>国星光电</strong>作为中国LED封装细分领域的龙头企业，公司多次荣获国内LED知名品牌、最佳封装企业品牌、中国LED企业国际竞争力TOP10、最佳表现LED上市公司、年度优秀上市公司、年度品牌企业等荣誉称号。公司全面推行国际质量体系和环境体系，通过了ISO9001、ISO14001、IATF16949、OHSAS18001、ISO/IEC 17025、计量体系六大体系认证。2018年，在全球LED封装领域，国星光电营业收入和市场占有率位列全球第八（IHS Markit）。</p><p>库存：大部分企业存货周转天数略有上升，但是变化不大</p><img src="国星-存货.png" width="80%" height="100%"><p>现金流质量：经过18年的下降后，19年明显上升，行业“经营活动产生的现金流量净额/营业收入”对比如下：</p><img src="国星-营收.png" width="60%" height="80%"><p>2019 年上半年公司实现营业收入 16.26 亿元，同比下降 8.87%，主要由于 LED 白光封装业务价格下降和客户调整；归母净利润 1.97 亿元，同比下降 12.39%，主要由于公司芯片业务行业竞争惨烈，净利润大幅下滑。公司当前市盈率15.37，股价处于低部区域。</p><h2>小结</h2><p>标明目前行业已经进入去库存后半段，经过几个季度消化之后，有望进入主动补库存阶段。三季度如果显示止跌企稳的话，叠加 Mini 背光/显示新需求放量，行业景气将重新来临，借此，上游三安光电和下游利亚德都有报表修复的预期。</p><p>向下空间不高，反转后向上空间很大，赔率很高。</p>]]></content>
      
      
      <categories>
          
          <category> stock </category>
          
          <category> finance </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 三安 </tag>
            
            <tag> 国星 </tag>
            
            <tag> 股票 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一文梳理2019年腾讯广告算法大赛冠军方案</title>
      <link href="/2019/09/14/tencent-ad-contest/"/>
      <url>/2019/09/14/tencent-ad-contest/</url>
      
        <content type="html"><![CDATA[<p>作为从本次比赛共157队伍中脱颖而出的冠军方案，评分达到87.9683，从数据清洗、模型构建、目标优化等有非常多值得学习的地方。比赛团队也挺有意思，分别来自哈工大、微软研究院和京东，算是学术界和工业界的强强联合，在多个数据竞赛中都有不错的名次。</p><blockquote><p>评委：“这是最接近腾讯真实业务的方案。”</p></blockquote><p>本文将从源码着手，深度解读该冠军方案是如何一步步从rough data清洗、特征工程到运用多种模型融合实现最佳效果的。作为一名数据竞赛经验薄浅的算法工程师，期望尽可能的将里面涉及到的知识、技巧、模型、算法作一个细致的总结，所以行文可能比较基础难免冗长。</p><h2>背景介绍</h2><p>作为国内领先的大数据营销平台，全新升级的腾讯广告，以更强大的全景连接、更全链的数字智慧、更友好的人本体验等三大核心能力，构建品牌与用户的智慧连接，助力广告主高效实现商业增长。而复杂的社交场景，多样的广告形态，以及庞大的人群数据，给实现这一目标带来了不小的挑战。为攻克这些挑战，腾讯广告也在不断地寻找更为优秀的数据挖掘方式和机器学习算法。<br>本次算法大赛<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>的题目是源于腾讯广告业务中一个面向广告主服务的真实业务产品 ——广告曝光预估。广告曝光预估的目的是在广告主创建新广告和修改广告设置时，为广告主提供未来的广告曝光效果参考。通过这个预估参考，广告主能避免盲目的优化尝试，有效缩短广告的优化周期，降低试错成本， 使广告效果尽快达到广告主的预期范围。比赛中使用的数据经过脱敏处理，通过本次大赛，我们旨在挑选出更为优秀的曝光预估算法以及遴选出杰出的社交广告算法达人。</p><h2>比赛赛题</h2><ol><li><p>数据<br>主要是三个日志文件，分别为：</p><ul><li>历史日志数据：广告请求时间、用户 id、广告位 id、竞价广告信息等</li><li>用户信息数据：用户 id、年龄、性别、地域、行为兴趣等</li><li>广告设置：广告操作信息、广告静态信息</li></ul></li><li><p>目标<br>本次竞赛提供历史 n 天的曝光广告的数据（特定流量上采样），包括对应每次曝光的流量特征（用户属性和广告位等时空信息）以及曝光广告的设置和竞争力分数；测试集是新的一批广告设置（有完全新的广告id，也有老的广告id修改了设置），要求预估这批广告的日曝光。</p></li><li><p>评价指标<br>评价指标由两部分组成，准确性指标和出价单调性指标。<br>准确性指标<strong>SMAPE</strong>衡量了预测的准确度：<br>$$ \textbf{SMAPE} = \frac{1}{n} \sum_{t=1}^{n}\frac{|F_t - A_t|}{(F_t+A_t)/2}$$<br>单调性指标<strong>MonoScore</strong>衡量了报价与曝光量的相关性，这是对应“由于竞价机制的特性，在广告其他特征不变的前提下，随着出价的提升，预估曝光值也 单调提升才符合业务直觉。”其中：<br>$$<br>\textbf{MonoScore} = \frac{1}{n} \sum_{k=1}^{n}\frac{(imp_0 - imp_k)(bid_0-bid_k)}{|(imp_0 - imp_k)(bid_0-bid_k)|}<br>$$<br>最终得分是将两个指标加权相加：<br>$$ \textbf{TotalScore} = \omega_1 * (1-\frac{\textbf{SMAPE}}{2}) + \omega_2*\frac{\textbf{MonoScore} + 1}{2}$$</p></li></ol><h2>数据初探</h2><p>这次比赛的数据非常原始，日志信息的<strong>raw data</strong>，因此原始数据是脏数据。那么，建模第一步必须是数据清洗，异常检测，重复缺失值等。第二步，建模，而这里面的数据并没有给定标签，需要统计曝光量。这里面大有学问，出价不同的广告不能视为同一个广告；24小时（0-24点）间隔内未修改的广告视为同一广告，如果有修改，那么修改时间点后的广告视为新的广告。详细的数据集解读可以参考CSDN上的技术博客<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup><sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>，对所有数据集的详细介绍见下图：</p>   <!-- ![](flowchart.png) -->   <img src="flowchart.png" width="100%" height="100%"><h2>冠军方案</h2><p>作者在github<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>上公开了源码,该库包含了比赛详细的介绍文件<code>guide.pdf</code>和数据集下载链接（百度网盘），再次感谢作者。下面是亲自跑一遍源码后进行的归纳总结。</p><h3>数据清洗</h3><p>首先在preprocessing.py进行数据前处理，主要是以下几个函数：</p><ul><li>parse_rawdata：<code>曝光日志、静态广告属性、用户信息、测试数据</code>都转化为Dataframe</li><li>construct_log：构造<code>曝光日志</code>，统计每一天各个广告的曝光量，同时将最后一天的数据择选出来</li><li>extract_setting：对<code>广告操作日志</code>进行日期纠正，缺失日期记录则copy填充</li><li>construct_train_data：构造训练集，根据<code>曝光日志</code>统计广告当天平均出价和曝光，通过crowd_direction和delivery_periods两个属性过滤其中未在<code>广告操作日志</code>出项的广告，并剔除出价过高（1000以上）和曝光过高（3000以上）的广告（这两个阈值怎么定的？）</li><li>construct_dev_data：构造验证集，输入为曝光日志中最后一天（[‘request_day’]==17974）的数据，根据<code>广告操作日志</code>剔除未出现操作记录、当天有操作记录和出价不唯一的广告的广告，奇怪的是源码里后面针对补全时间记录的广告操作日志又进行了一次未出现操作记录的过滤，这里有部分过滤重复，但没有错误，最终的dev_df也填补了缺失日期的记录。最后，构造了虚假广告用来测试单调性，这一点。</li><li>最后，对各个数据集merge<code>广告静态特征</code>。总共生成四个数据集：<ul><li>train_dev_df：从广告日志+广告操作文件+广告静态文件提取出的数据集中减去最后一天的数据</li><li>train_df：训练集，从广告日志+广告操作文件+广告静态文件聚合提取出的<ins><strong>最全数据集</strong></ins></li><li>dev_df：验证集，最后一天的广告数据</li><li>test_df：直接读取的test数据<br>这样切分的一个用处是，通过train_dev_df和dev_df进行有监督的模型训练，再通过train_df和test_df进行测试。</li></ul></li></ul><h3>特征提取</h3><p>在extract_feature.py特征提取包括人群定向、投放时段、多值特征的主副键（即两两特征之间的数量统计量，主要是以ID为基础统计，例如f1=aid，f2=uid，k=100，则表示访问该广告最多的前100名用户）、历史统计（例如，最近一天该广告的曝光量，时间越近相关性越大）、聚合统计（例如某商品的不同用户访问次数）、五折统计（shuffle后分为五折计算均值、中位数，不知道这多大用处？）以及uid和good_id等ID特征之间的word2vec和deepwalk embedding特征。</p><h3>格式转换</h3><p>最后在convert_format.py中，分别对训练集和测试集进行了去重、fillna、归一化以及将Word2Vec和DeepWalk得到的embedding拼接起来，并且掩盖到5%的广告。为什么掩盖掉5%的广告，作者给出的解释是为了保证训练集中也能出现无曝光的广告。新广告是没有历史信息的，所以如何构造新广告的特征，对新广告进行历史和整体性的描述成了提分的关键。这种处理主要解决以下两个问题：</p><ol><li>只有在日志中曝光过的广告才会有相应的嵌入向量，通过广告有无嵌入向量，会泄露了无曝光广告的标签；</li><li>测试数据中存在曝光非0但无嵌入向量的广告，这在训练集中是不存在的，导致训练测试不一致。</li></ol><!-- ### 小结初次拿到这个赛题，容易一头雾水。而该团队本身经过多次数据竞赛的丰富经验，在此次竞赛中也凸显出来。如何根据题目要求构建有标签的数据集，如何数据清洗和特征工程，如果规避数据泄露以及数据集构建上有非常多值得借鉴的地方，细节上，Dataframe的聚合操作、字典统计、大文件处理时的gc。 --><h2>模型解读</h2><blockquote><p>俞士纶（Philip S. Yu）教授评价说 “冠军队伍已经在有意无意使用‘广度学习’ 的方法”。</p></blockquote><p>该方案采用的模型组合包括CIN（xDeepFM）、Key-Value、Word2Vec和DeepWalk四种模型单元分别提取特征，然后concat输入到MLP中训练，模型框架如下图所示：<br><img src="framework.png" width="100%" height="100%"></p><p>源码中训练的入口为<code>train.py</code>，从该文件代码可知，经过特征工程后提取的特征类型有single_features、cross_features、multi_features、dense_features、kv_features。与此同时，针对不同特征使用不同的子模型进行处理，特征数据类型介绍所示：</p><table><thead><tr><th style="text-align:left">特征类型</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left">single_features</td><td style="text-align:left">单值特征，年龄、ID、性别等等</td></tr><tr><td style="text-align:left">cross_features</td><td style="text-align:left">交叉特征，与single_features有很大重复</td></tr><tr><td style="text-align:left">multi_features</td><td style="text-align:left">多值特征，各种组合特征，与上面两个特征无重叠</td></tr><tr><td style="text-align:left">dense_features</td><td style="text-align:left">稠密特征，deepwalk、word2vec和投放时段特征</td></tr><tr><td style="text-align:left">kv_features</td><td style="text-align:left">key-values特征，历史、统计特征</td></tr></tbody></table><p>由上可以看出，除了single_features、cross_features有大部分数据重复，其他相互之间没有重叠特征。为何特征重复？可以参考xDeepFM的模型，作用应该是类似增加一个Linear单元。从CIN.py代码看，cross_features和multi_features都会输入到CIN网络（<code>_build_extreme_FM</code>函数）中，然后dnn_input将CIN的输出、single_features的直接嵌入、kv_features以及dense_features以concatenate的方式结合起来输入到后端的MLP中。下面分别介绍各个子网络。</p><h3>压缩交互网络（CIN）</h3><p>要理解CIN网络，首先得理解FM因式分解机模型。FM旨在解决大规模稀疏数据下的特征组合问题，那么大规模稀疏数据是怎么来的呢？举个例子，用户访问某网站的日志数据中，我们可以发现许多特征是类别特征，性别、爱好、地址等等，而在特征处理过程中，通常会对categorical型特征进行one-hot编码，这必然带会导致特征空间稀疏性变大。在数据稀疏性的现实情况下，我们如何去利用这些特征来提升learning performance？<br>大量的研究和实际数据分析结果表明：某些特征之间的关联信息（相关度）对事件结果的的发生会产生很大的影响。从实际业务线的广告点击数据分析来看，也证实了这样的结论。而表示特征之间的关联，最直接的方法的是构造组合特征。样本中特征之间的关联信息在one-hot编码和浅层学习模型（如LR、SVM）是做不到的。目前工业界主要有两种手段得到组合特征：</p><ol><li>人工特征工程（数据分析＋人工构造，各种统计merge）；</li><li>通过模型做组合特征的学习（深度学习方法、FM/FFM方法）</li></ol><p>FM本质上是回归模型，不过是从一维延展到了高维，以二维多项式组合为例，其公式如下：<br>$$y(x) = \omega_0 + \sum_{i=1}^{n} \omega_i{x_i} + \sum_{i=1}^{n} \sum_{j=i+1}^{n} \omega_{ij}x_ix_j \tag{1}$$</p><p>其中，$n$代表样本的特征数量，$x_i$ 是第$i$个特征的值，$\omega_0$、$\omega_i$、$\omega_{ij}$是模型参数。从公式$(1)$可以看出，组合特征的参数一共有 $n(n−1)/2$个，每个参数$\omega_{ij}$的训练需要大量$x_i$和 $x_j$ 都非零的样本。然而，由于样本数据本来就比较稀疏，满足$x_i$和 $x_j$都非零的样本将会非常少。训练样本的不足，很容易导致参数 $\omega_{ij}$ 不准确，最终将严重影响模型的性能。<br>如何解决二次项参数的训练问题呢？矩阵分解提供了一种解决思路。关于FM中矩阵分解可以参见《深入FFM原理与实践》<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup>。通过对参数$\omega_{ij}$的矩阵（对称矩阵）进行矩阵分解，将$\omega_{ij}$用 $\left&lt; \textbf{v}_i,\textbf{v}_j \right&gt;$内积的方式来表达，那么公式$(1)$可以如下表达：</p><p>$$y(x) = \omega_0+ \sum_{i=1}^{n} \omega_i{x_i} + \sum_{i=1}^{n} \sum_{j=i+1}^{n}\left&lt;\textbf{v}_i,\textbf{v}_j\right&gt;x_ix_j \tag{2}$$</p><p>其中$\mathbf v_{i}$是第 $i$ 维特征的隐向量，而隐向量的长度为$k (k\ll n)$,这样二次项的参数数量减少为$kn$个,远少于多项式模型的参数数量，同时之前样本组合确实造成参数$\omega_{j}$的情况现在可以通过隐向量的方式学习到有效值。当然，这种变换方式也降低了计算复杂度，详细证明可以参见博客<sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup>。</p><p>对于一个基于CTR预估的推荐系统，最重要的是学习到用户点击行为背后隐含的特征组合。在不同的推荐场景中，低阶组合特征或者高阶组合特征可能都会对最终的CTR产生影响。广度模型（LR/ FM/ FFM）一般只能学习1阶和2阶特征组合；而深度模型（FNN/PNN）一般学习的是高阶特征组合。Goggle在2016年提出的 Wide&amp;Deep 模型同时考虑了两者。Wide$Deep层次结构图如下所示：<br><img src="wide-deep-structure.png" width="100%" height="100%"><br>但Wide部分需要人工参与的特征工程，于是DeepFM模型应运而生，DeepFM是用FM模型取代Wide的LR部分，Wide &amp; Deep中LR部分和Deep部分是完全独立的，LR部分的输入是稀疏特征，Deep部分稀疏特征先经过embeding层变成embeding向量，再传入隐层。DeepFM中每一个feature field经过embeding层转化为一个隐向量，多个特征field concat成一个密集向量分别作为FM部分和Deep部分的输入。FM部分将每个field的隐向量两两组合，最后在输出层和Deep部分输出concat成最终的输出层。整体上来说，DeepFM有以下三大优点：</p><ol><li>DeepFM可以end-to-end训练，不需要任何的特征工程。FM作为低阶特征，DNN作为高阶特征。</li><li>训练更加高效，Wide和Deep两者共享同一个输入和embedding向量。与Wide &amp; Deep相比，由于Wide &amp; Deep需要人工的进行特征工程，因此增加了模型的复杂度。</li><li>CTR预测结果更准确。</li></ol><p>关于DeepFM模型更详细的介绍、模型变种和评估对比可以参见另一篇博客<sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup>。从FM，到DeepFM，现在我们进入正题CIN，即<a href="https://arxiv.org/abs/1803.05170" target="_blank" rel="noopener">XdeepFM</a>。首先看看xDeepFM模型的结构：<br><img src="xdeepfm.png" width="80%" height="80%"><br>由上图可知,xDeepFM基本框架依然基于标准的 Embedding&amp;MLP，其中 Linear、Plain DNN 分别类似 Wide 和 Deep 部分，而 CIN 部分是我们要讨论的重点。CIN（Compressed Interaction Network），中文名压缩交互网络，从名字可预期模型使用类pooling压缩操作，以及特征交互方法。CIN的输入是所有field的embedding向量构成的矩阵$X^0 \in R^{m×D}$，该矩阵的第$i$行对应第$i$个field的embedding向量，并假设由M个field的embedding向量维度都为D。<br><img src="CIN-1.png" width="50%" height="30%"><br>CIN网络架构如上图所示，从$H_1-H_k$每一层输入都是$X_0$和上一层的输出$X_{k-1}$，且每一层都相当于是提取了更高一维的交叉特征，它们层层之间的计算为如下公式：<br>$$X_{h,*}^{k} = \sum_{i=1}^{H_k−1} \sum_{j=1}^{m} W_{ij}^{k,h} (X_{i,*}^{k−1} \circ X_{j,*}^{0}) \tag{3}$$<br>其中，$\circ$ 表示哈达玛积，即两个矩阵或向量对应元素相乘得到相同大小的矩阵或向量。$X_{j,*}^{0}$表示$X_0$矩阵的第j行，简单可以理解为两个X矩阵的哈达玛积通过W矩阵变换为输出矩阵的一行，多个变换矩阵W映射为新的输出矩阵。<br>由于上述计算公式可能不是很好理解，论文作者给出了另一种更加方便理解的视角。在计算 $X^{k+1}$ 时，定义一个中间变量 $Z^{k+1} \in R^{H_k×m×D}$，而 $Z^{k+1}$ 是一个数据立方体，由D个数据矩阵堆叠而成，其中每个数据矩阵是由 $X^k$ 的一个列向量与 $X^0$ 的一个列向量的外积运算而得，如下图所示。$Z^{k+1}$ 的生成过程实际上是由 $X^k$ 与 $X^0$ 沿着各自embedding向量的方向计算外积的过程。<br><img src="CIN-2.png" width="50%" height="30%"><br>$Z^{k+1}$ 可以被看作是一个宽度为m、高度为 $H_k$、通道数为D的图像，在这个虚拟的图像上施加一些卷积操作即得到 $X^{k+1}$。 $W^{k,h}$ 是其中一个卷积核，总共有 $H_{k+1}$个不同的卷积核，因而借用CNN网络中的概念，$X^{k+1}$ 可以看作是由$H_{k+1}$个feature map堆叠而成，如下图所示。<br><img src="CIN-3.png" width="50%" height="30%"><br>正是通过卷积操作，CIN把第k+1层由$H_k×m$个向量压缩到了$H_{k+1}$个向量，起到了防止维数灾难的效果。值得注意的是，这种按列计算外积后进行转换，与公式（3）的方式按行计算示哈达玛积的变换在三维立方体$Z^{k+1}$上是等效的。<br>CIN最终学习出的特征交互的阶数是由网络的层数决定的，而且交互发生在向量级上，每一层隐层都通过一个池化操作连接到输出层，从而保证了输出单元可以见到不同阶数的特征交互模式。同时不难看出，CIN的结构与循环神经网络RNN是很类似的，即每一层的状态是由前一层隐层的值与一个额外的输入数据计算所得。不同的是，CIN中不同层的参数是不一样的，而在RNN中是相同的；RNN中每次额外的输入数据是不一样的，而CIN中额外的输入数据是固定的，始终是$X^0$。</p><h3>Key-Value</h3><p><a href="https://arxiv.org/abs/1606.03126" target="_blank" rel="noopener">Key-Value</a>记忆网络<sup class="footnote-ref"><a href="#fn8" id="fnref8">[8]</a></sup>是Facebook 在 2016 年 6 月发表的一篇文章，相比之前的两篇可以说是更加完美的将 Memory Networks 应用的了 QA 任务上。那么，我们从facebook的第一篇文章开始梳理一下记忆网络的知识。</p><h4>Memory Network</h4><p>传统的深度学习模型（RNN、LSTM、GRU 等）使用 hidden states 或者 Attention 机制作为他们的记忆功能，但是这种方法产生的记忆太小了，无法精确记录一段话中所表达的全部内容，也就是在将输入编码成 dense vectors 的时候丢失了很多信息（例如单词顺序）。所以 FaceBook 在 2014 年发表的论文 “Memory Networks”就提出了一种可读写的外部记忆模块，并将其和 inference 组件联合训练，最终得到一个可以被灵活操作的记忆模块。其框架如下：<br><img src="memory-net.jpg" width="80%" height="80%"><br>可以看到模型基本分为四个模块，<strong>I</strong>（nput）、<strong>G</strong>（eneralization）、<strong>O</strong>（utput）、<strong>R</strong>（esponse），其功能为：</p><ul><li><strong>I</strong> 模块将输入的文本编码成向量</li><li><strong>G</strong> 模块根据输入的向量对 memory 进行读写操作，即对记忆进行更新</li><li><strong>O</strong> 模块会根据 Question对 memory 的内容进行权重处理，将记忆按照与 Question 的相关程度进行组合得到输出向量</li><li><strong>R</strong> 模块根据输出向量编码生成一个自然语言的答案</li></ul><p>根据原文，<strong>I</strong> 模块就是一个embedding lookup，将原始文本（先验知识）转化为词向量的形式。<strong>G</strong> 模块则是直接将输入的向量存储在 memory 数组的下一个位置，不做其他操作。 <strong>O</strong> 模块根据输入的问题向量在所有的记忆中选择出 topk 相关的记忆，具体选择方式为：先选记忆中与输入问题向量$x$最相关的memory向量$mo_1$，然后选择和$x$以及$mo_1$最相关的$mo_2$，迭代选择出TopK个memory向量即可。最后通过<strong>R</strong> 模块生成答案，具体方式为通过评分函数将$[x, mo_1,…mo_k]$与词表中每个单词进行评分，得分最大的单词作为回答。详细的评分函数以及模型训练的损失函数可以学习原文。</p><h4>End-To-End Memory Networks</h4><p>上文提到的作为第一个普适性的框架模型，也有几点不完善的地方：</p><ul><li>直接将原始文本进行向量化并保存，原始文本大的话内存消耗巨大</li><li><strong>O</strong> 和 <strong>R</strong> 部分评分函数无法进行反向传播训练<br>所以，Facebook AI 在 Memory networks 之后提出了一个更加完善的模型<a href="https://arxiv.org/abs/1503.08895" target="_blank" rel="noopener"><strong>End-To-End Memory Networks</strong></a><sup class="footnote-ref"><a href="#fn9" id="fnref9">[9]</a></sup>，论文中提出了单层和多层的结构，单层的架构如下图：<br><img src="e2e-memory.jpg" width="80%" height="80%"><br>对比上文的IGOR四个模块，这次模型架构稍微有些不同：</li></ul><ol><li>将原文分别嵌入到Input和Output两部分记忆模块，其中input用来与Question 编码进行计算相关性，Output 则与该相关性进行加权求和得到输出向量</li><li>输出$o$不再是直接进入到Response，而是先与问题$q$进行加和，再与 字典W 相乘，经过一个 softmax 函数产生各个单词是答案的概率，借此可以使用交叉熵损失函数最为目标函数进行训练</li></ol><p>以此为基础模块，以堆叠的方式可以实现多层端到端记忆网络：<br><img src="multi-e2e.jpg" width="60%" height="40%"><br>更详细的模型设计和模块介绍可以参考原文和记忆网络-知乎专栏<sup class="footnote-ref"><a href="#fn10" id="fnref10">[10]</a></sup>。</p><h4>Key-Value Memory Networks</h4><p>该模型是 Facebook 在 2016 年的一篇文章上发表的，相比上文的两个可以说是更加完美的将 Memory Networks 应用的了 QA 任务上。<strong>End-To-End Memory Networks</strong> 实现了记忆网络的端到端的模型可训练，但效果提升并不明显，而Key-Value在模型架构上进一步创新，使其可以更好的存储 QA 所需要的先验知识。<br><img src="key-value.png" width="100%" height="100%"><br><strong>Key-Value</strong>用Key addressing和Value reading分别代表End-To-End中的Input和Output部分，所有的记忆都被存储在Key-Value memory中，key负责寻址lookup，也就是对memory与Question的相关程度进行评分，而value则负责reading，也就是对记忆的值进行加权求和得到输出。整个模型的运行机制为：</p><ul><li><strong>key hashing</strong>：首先根据输入的问题从知识源中检索出与问题相关的facts，检索的方法可以是至少包含一个相同的实体等多种方法。也就是上图中下面的绿色部分，相当于一个记忆的子集。这部分工作可以在与处理数据的时候进行。然后将其作为模型输入的一部分训练的时候输入模型即可。</li><li><strong>key addressing</strong>：寻址，也就是对memory进行相关性评分。用key memory与输入的Question相乘之后做softmax得到一个概率分布。概率大小等效于相关程度。其中$A \Phi_X$ 、$A \Phi_K$ 和 $A \Phi_V$ 都是embedding模型，对输入问题、key、Value进行编码得到其向量表示。</li><li><strong>Value Reading</strong>：有了相关性评分$P_{h_i}$，接下来就对value memory $A\Phi_V$ 进行加权求和即可，得到一个输出向量。</li></ul><p>这样就完成了一个hop操作，接下来跟<strong>End-To-End</strong>一样，将输出向量 $o$ 与输入问题的向量表示 $q$ 相加，经过 $R_j$ 矩阵进行映射，在作为下一层的输入，重复循环得到$q_{H+1}$，为问题答案的嵌入式向量表示。而$B\Phi_Y$是候选答案寻址空间，可以和字典空间一模一样，相当于在领域知识库内搜索答案，也可以是另一个领域外的候选词库，可以发现新词的答案。最终都是通过交叉熵作为损失函数，端到端的对模型进行反向传播训练。整个过程看下来其实跟end-to-end模型很相似，最关键的地方加在于Key-Value的memory如何进行表示，这也是本模型的创新所在。<br>Key-Value memory的好处在于可以方便的对先验知识进行编码，这样就可以让每个领域的人都方便的将本领域内的一些背景知识编码进记忆中，从而训练自己的QA系统，相比于end-to-end模型将相同的输入经过不同的矩阵分别编码到Input memory和Output memory，Key-Value则选择对输入首先进行一个（key， value）形式的表示，然后再分别编码进入key和value两个memory模块，这样就有了更多的变化和灵活性。我们可以按照自己的理解对数据进行key索引和value记忆，而不需要完全依赖于模型的embedding矩阵，这样也可以使模型更方便的找到相关的记亿并产生与答案最相近的输出。论文中根据不同形式的输入（KB或者wiki文章），提出了几种不同的编码方式，感兴趣的可以<a href="https://arxiv.org/abs/1606.03126" target="_blank" rel="noopener">参见原文</a>。<br>回到主题中来，Key-Value在这个方案中是如何被应用的？通过作者放出的PPT可以看到，作者通过Key-Value Memory的模型实现浮点数到向量的映射，不过采用的是下图的精简模型：<br><img src="key-value2.png" width="100%" height="100%"><br>剔除掉了迭代$Hop$部分和Response，毕竟只需要得到输入特征的嵌入式表达向量，通过索引方式设定$k_i$键值，最终需要训练得到的参数就是整个Key-Value Memory中的Value（即vector embedding矩阵）。下面再看看源码，其实现部分在<code>CIN.py</code>的78行，如下所示：</p><pre class="line-numbers language-language-python"><code class="language-language-python">if hparams.kv_features is not None:    index=[i/hparams.kv_batch_num for i in range(hparams.kv_batch_num+1)]        index=tf.constant(index)      distance=1/(tf.abs(self.kv_features[:,:,None]-index[None,None,:])+0.00001)    weights=tf.nn.softmax(distance,-1) #[batch_size,kv_features_size,kv_batch_num]    kv_emb=tf.reduce_sum(weights[:,:,:,None]*kv_emb_v2[None,:,:,:],-2)    kv_emb=tf.reshape(kv_emb,[-1,len(hparams.kv_features)*hparams.k])    dnn_input.append(kv_emb)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>该段代码首先通过index将浮点数的区间（0~1）划分为 N=20 个子区间，每一个代表一个键值进行索引，然后计算每个样本的每个特征值与这20个区间的距离。这里需要注意的是weights已经增加了一个维度，每个kv_features都计算了与21个键值index的距离，然后每一个权重值与kv_emb_v2嵌入式特征矩阵相乘累加，reshape后得对最终的特征矩阵kv_emb，这里面的维度很容易出错，最终每个kv特征被嵌入式到hparams.k=16的向量空间中。</p><blockquote><p>这里不由得产生了一个问题，<strong>key-value与连续值分桶嵌入式的区别是什么，为何模型要采用key-value？</strong></p></blockquote><h3>Word2Vec</h3><p>Word2Vec 是从大量文本语料中以无监督的方式学习语义知识的一种模型，它最初被大量地用在自然语言处理（NLP）中。那么它是如何帮助我们做自然语言处理呢？Word2Vec 其实就是通过学习文本来用词向量的方式表征词的语义信息，即通过一个嵌入空间使得语义上相似的单词在该空间内距离很近。Embedding 其实就是一个映射，将单词从原先所属的空间映射到新的多维空间中，也就是把原先词所在空间嵌入到一个新的空间中去。举个例子，cat 这个单词和 kitten 属于语义上很相近的词，而 dog 和 kitten 则不是那么相近，iphone 这个单词和 kitten 的语义就差的更远了。通过对词汇表中单词进行这种数值表示方式的学习（也就是将单词转换为词向量），能够让我们基于这样的数值进行向量化的运算从而能够表征语义信息。<br>Word2Vec 模型中，主要有 Skip-Gram 和 CBOW 两种模型，从直观上理解，Skip-Gram 是给定 input word 来预测上下文。而 CBOW 是给定上下文，来预测 input word。本篇文章仅讲解 Skip-Gram 模型。<br><img src="word2vec.jpg" width="100%" height="100%"><br>大部门嵌入式情况下都是使用Skip-Gram模型，其形式非常简单，模型架构如下图所示：<br><img src="skip-gram.png" width="100%" height="100%"><br>假设从我们的训练文档中抽取出10000个唯一不重复的单词组成词汇表，对这10000个单词进行one-hot编码，得到的每个单词都是一个10000维的向量，向量每个维度的值只有0或者1。而对模型训练的训练样本是 （input word, output word） 这样的单词对，训练时通过softmax函数将模型输出转化为10000维的向量，与output word 的one-hot编码对应。模型训练完后得到的隐藏层参数矩阵为$W$，它的维度为10000*k（神经元个数，等效于嵌入式的特征空间维数），而由于输入为one-hot编码，隐藏层实现的功能其实类似于一个查找标，每一个向量从矩阵$W$中查找到其在隐空间中的向量表示，于是$W$的每一行就是一个原始变量的嵌入式向量，即原始位点在转换空间后的坐标。这时候大家容易发现一个问题，如果文本中某个词特别多怎么办，例如“the”在文章中出现频次超高，那模型就需要对高频词进行抑制，方法包括对高频次单词进行抽样来减少训练样本的个数、将常见的单词组合（word pairs）或者词组作为单个“words”来处理以及<strong>negative sampling</strong>。<br>关于Word2Vec更多朴实近人的介绍参考博客<sup class="footnote-ref"><a href="#fn11" id="fnref11">[11]</a></sup>。</p><h3>Deepwalk</h3><p>Deepwal源自图理论，关于图网络不得不提的是清华大学孙茂松组的图网络综述<sup class="footnote-ref"><a href="#fn12" id="fnref12">[12]</a></sup>，该文总结了近年来图神经网络领域的经典模型与典型应用，对于希望快速了解这一领域的读者，不妨先从这篇文章看起。 而且该文还提到“<strong>DeepWalk、LINE、SDNE 等方法在网络表示学习领域取得了很大的成功，然而，这些方法在计算上较为复杂并且在大规模的图上并不是最优的，GNN旨在解决这些问题。</strong>”也就是说Deepwalk是有一定局限性的模型，当然这并不是文本的重点，本文关心的是Deepwalk的理论知识以及作者是如何应用Deepwalk的思想来解决问题的。<br>对于一个图 $G$，我们一般用点的集合 $V$ 和边的集合 $E$ 来描述。即为 $G(V,E)$。其中 $V$ 为我们数据集里面所有的点 $(v_1,v_2,…v_n)$。对于 $V$中的任意两个点，可以有边连接，也可以没有边连接。我们定义权重 $w_{ij}$为点 $v_i$和点 $v_j$之间的权重，并且通常假设是无向图，有 $w_{ij}=w_{ji}$。最简单的图示例如下所示：<br><img src="graph.png" width="100%" height="100%"><br>左图共有7个顶点，两个顶点相连则表示为$w_{ji}=w_{ji}=1$，这时将$W$称为邻接矩阵，显而易见其为对称矩阵。将左图转化为矩阵后，就可以利用矩阵的运算方便地进行图计算。值得一提的是，$w_ji$表征的是两个点之间的关系度量，当然可以有欧式距离、联合概率等多种度量方式。<br>Deepwalk来源于《DeepWalk: Online Learning of Social Representations》这篇论文，它的思想简单易懂，主要借鉴了word2vec，产生句子的方式为从网络中随机一个节点，然后以此节点为起点，按概率从其邻居中选择下一个节点，迭代下去将得到的K的节点作为word2vec中的句子。于是，将网络结构通过Random walk的方式，转换为类似“sentence”的节点序列的形式，再借用Skim-gram模型实现节点的嵌入式向量表达。</p><h2>总结</h2><p>本文详细介绍了冠军方案中涉及到的各个子模型的原理和用途，包括如何提取特征、提取了什么特征以及提取特征的意义。但由于经验的不足，尚未从特征角度阐述为什么要提取这些特征，以及如何通过数据EDA来辅助特征工程，构造出有意义的特征并最终提升模型的效果。</p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>2019腾讯广告算法大赛，<a href="https://algo.qq.com/application/home/home/index.html" target="_blank" rel="noopener">https://algo.qq.com/application/home/home/index.html</a> <a href="#fnref1" class="footnote-backref">↩</a></p></li><li id="fn2" class="footnote-item"><p>Guiliano，数据集探索博客：<a href="https://blog.csdn.net/jliang3/article/details/90610865" target="_blank" rel="noopener">https://blog.csdn.net/jliang3/article/details/90610865</a> <a href="#fnref2" class="footnote-backref">↩</a></p></li><li id="fn3" class="footnote-item"><p>鱼遇雨欲语与余，原作者知乎专栏：<a href="https://zhuanlan.zhihu.com/p/69351598" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/69351598</a> <a href="#fnref3" class="footnote-backref">↩</a></p></li><li id="fn4" class="footnote-item"><p>大赛冠军源码， <a href="https://github.com/guoday/Tencent2019_Preliminary_Rank1st" target="_blank" rel="noopener">https://github.com/guoday/Tencent2019_Preliminary_Rank1st</a> <a href="#fnref4" class="footnote-backref">↩</a></p></li><li id="fn5" class="footnote-item"><p>美团，FM，<a href="https://tech.meituan.com/2016/03/03/deep-understanding-of-ffm-principles-and-practices.html" target="_blank" rel="noopener">https://tech.meituan.com/2016/03/03/deep-understanding-of-ffm-principles-and-practices.html</a> <a href="#fnref5" class="footnote-backref">↩</a></p></li><li id="fn6" class="footnote-item"><p>FM博客，<a href="https://www.csuldw.com/2019/02/08/2019-02-08-fm-algorithm-theory/" target="_blank" rel="noopener">https://www.csuldw.com/2019/02/08/2019-02-08-fm-algorithm-theory/</a> <a href="#fnref6" class="footnote-backref">↩</a></p></li><li id="fn7" class="footnote-item"><p>DeepFM博客，<a href="https://www.csuldw.com/2019/07/26/2019-07-25-introduction-of-deepFM/" target="_blank" rel="noopener">https://www.csuldw.com/2019/07/26/2019-07-25-introduction-of-deepFM/</a> <a href="#fnref7" class="footnote-backref">↩</a></p></li><li id="fn8" class="footnote-item"><p>Facebook，记忆网络，<a href="https://arxiv.org/abs/1606.03126" target="_blank" rel="noopener">https://arxiv.org/abs/1606.03126</a> <a href="#fnref8" class="footnote-backref">↩</a></p></li><li id="fn9" class="footnote-item"><p>Facebook，端到端记忆网络，<a href="https://arxiv.org/abs/1503.08895" target="_blank" rel="noopener">https://arxiv.org/abs/1503.08895</a> <a href="#fnref9" class="footnote-backref">↩</a></p></li><li id="fn10" class="footnote-item"><p>记忆网络-知乎专栏，<a href="https://zhuanlan.zhihu.com/p/29679742" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/29679742</a> <a href="#fnref10" class="footnote-backref">↩</a></p></li><li id="fn11" class="footnote-item"><p>AI研习社，Word2Vec结构，<a href="https://cloud.tencent.com/developer/article/1065628" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1065628</a> <a href="#fnref11" class="footnote-backref">↩</a></p></li><li id="fn12" class="footnote-item"><p>清华大学孙茂松组，图网络综述，<a href="https://arxiv.org/abs/1812.08434" target="_blank" rel="noopener">https://arxiv.org/abs/1812.08434</a> <a href="#fnref12" class="footnote-backref">↩</a></p></li></ol></section>]]></content>
      
      
      <categories>
          
          <category> model </category>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 腾讯广告 </tag>
            
            <tag> 竞赛 </tag>
            
            <tag> embedding </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
